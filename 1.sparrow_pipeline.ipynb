{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPArrOW pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparrow as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in the data\n",
    "\n",
    "The example dataset for this notebook will be downloaded and cached using `pooch` via `sparrow.dataset.registry`.\n",
    "\n",
    "The image is then read in to a `SpatialData` object (see https://spatialdata.scverse.org/en/latest/ for more information).\n",
    "\n",
    "We also use the `bioio` package to read in the image, see https://bioio-devs.github.io/bioio/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "from sparrow.datasets.registry import get_registry\n",
    "\n",
    "unit_testing = True\n",
    "\n",
    "# change this path. It is the directory where the spatialdata .zarr will be saved.\n",
    "OUTPUT_DIR =  tempfile.gettempdir()\n",
    "\n",
    "registry=get_registry()\n",
    "path_image = registry.fetch( \"transcriptomics/resolve/mouse/20272_slide1_A1-1_DAPI.tiff\" )\n",
    "path_coordinates = registry.fetch(\"transcriptomics/resolve/mouse/20272_slide1_A1-1_results.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioio import BioImage\n",
    "\n",
    "img=BioImage( path_image )\n",
    "print(img.dims)\n",
    "img.dask_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = img.dask_data.squeeze( ( 0, 2 ) ) # squeeze T and Z dimension\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "\n",
    "from spatialdata import SpatialData, read_zarr\n",
    "\n",
    "sdata = SpatialData()\n",
    "\n",
    "zarr_path = os.path.join( OUTPUT_DIR, f\"sdata_{uuid.uuid4()}.zarr\")\n",
    "\n",
    "sdata.write( zarr_path )\n",
    "sdata = read_zarr( sdata.path )\n",
    "\n",
    "sdata.is_backed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata=sp.im.add_image_layer(\n",
    "    sdata,\n",
    "    arr = array,\n",
    "    dims=( \"c\", \"y\", \"x\" ),\n",
    "    output_layer=\"raw_image\",\n",
    "    overwrite=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[ \"raw_image\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.pl.plot_image( sdata, img_layer = \"raw_image\" , crd = [0, 6432, 0, 6432], figsize = (5,5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or alternatively via spatialdata plot\n",
    "import spatialdata_plot\n",
    "\n",
    "sdata.pl.render_images( \"raw_image\" ).pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from napari_spatialdata import Interactive\n",
    "\n",
    "#Interactive( sdata )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excercise, add as multiscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata=sp.im.add_image_layer(\n",
    "    sdata,\n",
    "    arr = array,\n",
    "    dims=( \"c\", \"y\", \"x\" ),\n",
    "    output_layer=\"raw_image\",\n",
    "    scale_factors=[ 2,2,2,2 ],\n",
    "    overwrite=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sdata[ \"raw_image\" ])  # Now it is a DataTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get associated dask array\n",
    "from sparrow.image._image import _get_spatial_element\n",
    "\n",
    "se=_get_spatial_element( sdata, layer=\"raw_image\" )\n",
    "se.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image preprocessing\n",
    "\n",
    "### 2.1 tiling correction and inpainting\n",
    "\n",
    "When working with RESOLVE data, the data is acquired in tiles, and the illumination within a tile isn't always constant. Sometimes one side of a tile is more illuminated than the other, influencing the downstream analysis greatly. RESOLVE assured us this isn't linked to the counts of the transcripts, but this can be checked further on.\n",
    "In general this step is not necessary for other datatypes (you can check this by plotting the complete image). \n",
    "\n",
    "Basic is a tool that can correct for this, and is used in this function. The size of the tile needs to be known in order to run the function. The dfault value for this function is the tile size of RESOLVe (2144).\n",
    "\n",
    "This step also corrects for black lines in between the tiles, by using inpainting. \n",
    "\n",
    "This step is very specific for RESOLVE data and should not be run when working with Merscope, Xenium,... data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata, flatfields = sp.im.tiling_correction(\n",
    "    sdata=sdata,\n",
    "    img_layer=\"raw_image\",\n",
    "    output_layer=\"tiling_correction\",\n",
    "    crd =  [0, 6432, 0, 6432],\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.pl.plot_image( sdata, img_layer=[ \"raw_image\", \"tiling_correction\" ], crd =  [2000, 6000, 2000, 6000], figsize=(10,10) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 min-max filtering and contrast enhancing\n",
    "The second step of the preprocessing the data includes a couple of steps:\n",
    "\n",
    "\n",
    "- A min max filter can be added. The goal of this function is to substract background noise, and make the borders of the nuclei/cells cleaner, plus it will delete the occasional debris. If you take the size too small, smaller then the size of your nuclei, the function will create donuts, with black spots in the center of your cells.  If the size of the min max filter is chosen too big, not enough background is substracted, so a tradeoff should be made. This might need some finetuning. For nuclei in RESOLVE data, 45-55 is a great starting point. Bigger for whole cells. Adapt this parameter to make sure you delete debris and HALO's. \n",
    "\n",
    "- We recommend to perform contrast enhancing on your image. SPArrOW does this by using histogram equalization (CLAHE function). The amount of correction needed can be decided by adapting the contrast_clip value. If the image is already quite bright, 3.5 might be a good starting value. For dark images, you can go up to 10 or even more. Make sure at the end the whole image is evenly illuminated and no cells are dark in the background.\n",
    " \n",
    "If you think you need more image processing, you can perform other steps using our map_image function. These images can then be added to the SpatialData object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = sp.im.min_max_filtering(\n",
    "    sdata=sdata,\n",
    "    img_layer=\"tiling_correction\",\n",
    "    output_layer=\"min_max_filtered\",\n",
    "    size_min_max_filter=45,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "sp.pl.plot_image(\n",
    "    sdata,\n",
    "    img_layer=\"min_max_filtered\",\n",
    "    crd=[ 2000,6000,2000,6000 ],\n",
    "    figsize=(5, 5),\n",
    "    )\n",
    "\n",
    "sdata = sp.im.enhance_contrast(\n",
    "    sdata=sdata,\n",
    "    img_layer=\"min_max_filtered\",\n",
    "    output_layer=\"clahe\",\n",
    "    contrast_clip=3.5,\n",
    "    chunks=20000,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "sp.pl.plot_image(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\",\n",
    "    crd=[2000,6000,2000,6000],\n",
    "    figsize=(5, 5),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from napari_spatialdata import Interactive\n",
    "\n",
    "#Interactive( sdata )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sdata=sp.im.enhance_contrast( sdata, img_layer=\"tiling_correction\", output_layer=\"test\", overwrite=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Custom distributed preprocessing of images using `sp.im.map_image` and `Dask`\n",
    "\n",
    "See https://docs.dask.org/en/stable/generated/dask.array.map_blocks.html and https://docs.dask.org/en/latest/generated/dask.array.map_overlap.html\n",
    "\n",
    "Set `blockwise==True` if you want to do distributed processing using `dask.array.map_blocks` or `dask.array.map_overlap`, set `blockwise==False` if your function is already distributed (e.g. when using `dask_image` filters https://image.dask.org/en/latest/dask_image.ndfilters.html.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "\n",
    "def _my_dummy_function(image: NDArray, parameter: int | float )->NDArray:\n",
    "    # input (1,1,y,x)\n",
    "    # output (1,1,y,x)\n",
    "    print(  f\"Type of the image is: {type(image)}\" )\n",
    "    print( image.shape )\n",
    "    return image*parameter\n",
    "\n",
    "fn_kwargs = { \"parameter\": 2 }\n",
    "\n",
    "sdata=sp.im.map_image(\n",
    "    sdata,\n",
    "    func = _my_dummy_function,\n",
    "    fn_kwargs=fn_kwargs,\n",
    "    img_layer = \"raw_image\",\n",
    "    output_layer=\"dummy_image\",\n",
    "    chunks = 5000,\n",
    "    blockwise=True, # if blockwise == True --> input to _my_dummy_function is a numpy array of size chunks, else it is a Dask array (with chunksize chunks)\n",
    "    depth = None, # if blockwise == True, and depth specified, will use map_overlap instead of map_blocks for distributed processing\n",
    "    overwrite=True,\n",
    "    dtype=np.uint16,\n",
    "    meta=np.array((), dtype=np.uint16),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparrow.image._image import _get_spatial_element\n",
    "\n",
    "_get_spatial_element( sdata, layer=\"raw_image\").data.compute()[ :, :10, :10 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_get_spatial_element( sdata, layer=\"dummy_image\").data.compute()[ :, :10,:10 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Segmenting the image\n",
    "\n",
    "For the segmentation, we here show an example on how to use cellpose, a deep learning network based on a UNET architecture.\n",
    "\n",
    "Multiple paramters need to be given as an input to the cellpose algorithm. We recommend tuning for the optimal segmentation quality. \n",
    " \n",
    "- diameter: Includes an estimate of the diameter of a nucleus. If put to none, cellpose will do the estimation by himself, but this estimation might take longer than the actual segmentation, and if often far off. Estimate around 7 micrometer (in this case 50 pixels at 0.138 micrometer per pixel) for a standard nucleus, and more for whole cells. Input is in pixels.This of course is tissue and method dependent. You can run the algorthim on a small piece (I[0:1000,0:1000] for example), to get an estimate of the size. However, this estimate isn't always accurate. So check the quality at the end. If you see all nuclei/cells are estimated too small, enlarge this parameter.\n",
    "- device: Defines the device you want to work on, if you only have cpu, you can skip this input parameter. If only having CPU, please tune the parameters on a small subset, and then make it to the big one. This might take a while for large images, but it should work. \n",
    "- flow_threshold: Indicates something about the shape of the masks, if you increase it, more masks with less round shapes will be accepted. Up to one:  I take it between 0.6 and 0.95, depending on the cell shapes. Higher is less round. Lower it if you start segmenting artefacts, up it if you miss non-round shaped cells.\n",
    "- mask_threshold: Indicates how many of the possible masks are kept. Making it smaller (up to -6), will give you more masks, bigger is less masks. I take it between 0 and -6. Be careful, you can oversegment: always check the quality \n",
    "- min_size: Indicates the minimal size of a nucleus. \n",
    "- If segmenting whole cells instead of nuclei, set the parameter model_type to 'cyto'.\n",
    "- If using nuclei together with whole cells, put model_type to 'cyto', make sure your image is 3D and and that the first channel is you complete cell staining and you second one is the nucleus channel, put the parameter channel to np.array([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from dask.distributed import Client, LocalCluster\n",
    "\n",
    "#cluster = LocalCluster(\n",
    "#    n_workers=1,\n",
    "#    threads_per_worker=10,\n",
    "#    memory_limit=\"32GB\",\n",
    "#)\n",
    "\n",
    "#client = Client(cluster)\n",
    "\n",
    "#print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from cellpose import models\n",
    "\n",
    "from sparrow.image import cellpose_callable\n",
    "\n",
    "gpu = False\n",
    "device = \"cpu\"\n",
    "model=models.CellposeModel( gpu=gpu, pretrained_model='nuclei', device = torch.device(device ) )\n",
    "\n",
    "#model = client.scatter(model) # pass a loaded model to _cellpose, but we scatter the model to avoid large task graph\n",
    "\n",
    "sdata = sp.im.segment(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\",\n",
    "    chunks=2048,\n",
    "    depth=200,\n",
    "    model=cellpose_callable,\n",
    "    # parameters that will be passed to the callable _cellpose\n",
    "    pretrained_model = model,\n",
    "    diameter=50,\n",
    "    flow_threshold=0.9,\n",
    "    cellprob_threshold=-4,\n",
    "    output_labels_layer=\"segmentation_mask\",\n",
    "    output_shapes_layer=\"segmentation_mask_boundaries\",\n",
    "    crd= [2000, 4000, 2000, 4000] if unit_testing else None,  # region to segment [x_min, xmax, y_min, y_max],\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "#client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.pl.plot_shapes( sdata, img_layer=\"clahe\", shapes_layer=\"segmentation_mask_boundaries\", figsize=( 5,5 ), crd = [  2000, 4000, 2000, 4000  ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or via spatialdata plot\n",
    "sdata.pl.render_images( \"clahe\" ).pl.render_labels( \"segmentation_mask\" ).pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is in general not recommended, but it is possible to expand cells beyond the segmented bodies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = sp.im.expand_labels_layer(\n",
    "    sdata,\n",
    "    labels_layer=\"segmentation_mask\",\n",
    "    distance=10,\n",
    "    output_labels_layer=\"segmentation_mask_expanded\",\n",
    "    output_shapes_layer=\"segmentation_mask_expanded_boundaries\",\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\",\n",
    "    shapes_layer=[\"segmentation_mask_boundaries\", \"segmentation_mask_expanded_boundaries\" ],\n",
    "    figsize=( 10,10 ),\n",
    "    crd = [  2000, 4000, 2000, 4000  ],\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Allocating  the transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4.1 Creating the count matrix\n",
    "In this step we\n",
    "- load in the transcipts: in the case of RESOLVE this is done with a specific loader. If no specific loader exist for your datatype, you can use the general `sp.io.read_transcripts` function.\n",
    "- allocate the transcripts to the correct cell. This allocation step creates the count matrix, saved in an anndata object.\n",
    "- Visual checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = sp.io.read_resolve_transcripts(sdata, output_layer=\"transcripts\", path_count_matrix=path_coordinates, overwrite=True)\n",
    "\n",
    "sdata = sp.tb.allocate(\n",
    "    sdata=sdata,\n",
    "    labels_layer=\"segmentation_mask\",\n",
    "    points_layer=\"transcripts\",\n",
    "    output_layer=\"table_transcriptomics\",\n",
    "    update_shapes_layers=False,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( type( sdata[ \"transcripts\" ] ) )\n",
    "sdata[ \"transcripts\" ].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excercise. \n",
    "\n",
    "- Run .compute() on the points layer. What is the data type of the resulting object?\n",
    "- Have a look at https://docs.dask.org/en/stable/dataframe.html.\n",
    "- Extract transformation from the points layer \"transcripts\" using `spatialdata.transformations.get_transformation`. See https://spatialdata.scverse.org/en/stable/generated/spatialdata.transformations.get_transformation.html\n",
    "- Now extract the transformation from the labels layer \"segmentation_mask\" and for the image layer \"clahe\".\n",
    "- Visualize the points layer and the labels layer using napari-spatialdata. Convince yourself they are registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[ \"table_transcriptomics\" ].X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[ \"table_transcriptomics\" ].to_df().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[ \"table_transcriptomics\" ].obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatialdata.models import TableModel\n",
    "\n",
    "sdata[ \"table_transcriptomics\" ].uns[TableModel.ATTRS_KEY ]\n",
    "#->table is annotated by labels layer \"segmentation_mask\"\n",
    "#->instance_key cell_ID matches labels in \"segmentation_mask\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "da.unique( sdata[ \"segmentation_mask\" ].data ).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.unique( sdata[ \"segmentation_mask\" ].data ).compute().shape\n",
    "# -> note that not all cells are in table layer \"table_transcriptomics\".\n",
    "# this is because not all cells could be assigned transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[ \"segmentation_mask_boundaries\" ].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\",\n",
    "    shapes_layer=\"segmentation_mask_boundaries\",\n",
    "    figsize=( 5,5 ),\n",
    "    crd = [  2000, 4000, 2000, 4000  ],\n",
    "    table_layer=\"table_transcriptomics\",\n",
    "    column = \"Axl\",\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# or via spatialdataplot\n",
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "gene_name =  \"Axl\"\n",
    "sdata.pl.render_labels(\"segmentation_mask\", color=gene_name, method=\"datashader\", fill_alpha=0.5).pl.show(\n",
    "    coordinate_systems=\"global\", ax=ax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from napari_spatialdata import Interactive\n",
    "\n",
    "#Interactive( sdata )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4.2 Transcript quality plot\n",
    "After we have created the anndata object, we control the transcript quality. \n",
    "\n",
    "First we create a plot to chekc if the transcript density is similar across the whole tissue. If this isn't the case, it can have multiple reasons. Most likely, there will be regions in which the transcript pick-up was less succesfull. Also gene panel choices can influence this plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = sp.im.transcript_density(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\",\n",
    "    points_layer=\"transcripts\",\n",
    "    output_layer=\"transcript_density\",\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.pl.plot_image( sdata, img_layer = [ \"clahe\", \"transcript_density\" ], figsize=( 10,10 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As not all of the image surface is segmented, there will be most likely transcripts that weren't assigned to a cell. \n",
    "For sure in the case of nucleus segmentation (like this example), this will be the case.\n",
    "\n",
    "In general, we hope to not lose any genes. So we hope there aren't genes with low abundances and a low proportion kept. In general we see a downward trend. The more a gene is measured, the less it is located in cells (in ratio).\n",
    "\n",
    "We also provide a table with the genes that are the least located in cells. If a lot of these genes are markers for the same celltype, the staining might be missing this celltype and you should for sure check this. However, it might also be the case that is celltype just has a lot of cytoplasm and you are only segmenting the nucleus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sp.pl.analyse_genes_left_out(\n",
    "    sdata,\n",
    "    labels_layer=\"segmentation_mask\",\n",
    "    table_layer=\"table_transcriptomics\",\n",
    "    points_layer=\"transcripts\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocess the table (AnnData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Filtering and Normalization\n",
    "\n",
    "The AnnData object is now processed:\n",
    "\n",
    "- calculate QC metrics\n",
    "- filter cells with less then 10 gene counts and genes with less then 5 cells (adaptations possible by adapting the function). These filtered cells are again filtered out of the shapes layer and the anndata obejct and saved in an extra shapes layer.\n",
    "- Normalization: For small gene panel (<500), we recommend to normalize the data based on the size of the segmented object (size_norm=True). For transcriptome-wide methods, we recommend standard library size normalization (size_norm=False). \n",
    "\n",
    "\n",
    "The last plot shows the size of the nucleus related to the counts. When working with whole cells, if there are some really big xcells with really low counts, they are probably not real cells and you should filter based on max size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform preprocessing.\n",
    "sdata = sp.tb.preprocess_transcriptomics(\n",
    "    sdata,\n",
    "    labels_layer=\"segmentation_mask\",\n",
    "    table_layer=\"table_transcriptomics\",\n",
    "    output_layer=\"table_transcriptomics_preprocessed\",  # write results to a new slot, we could also write to the same slot (when passing overwrite==True).\n",
    "    min_counts=10,\n",
    "    min_cells=5,\n",
    "    size_norm=True,\n",
    "    n_comps=50,\n",
    "    overwrite=True,\n",
    "    update_shapes_layers=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[ \"table_transcriptomics_preprocessed\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[ \"table_transcriptomics_preprocessed\" ].to_df().mean( axis=0 ).head() # mean ~ 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[ \"table_transcriptomics_preprocessed\" ].to_df().std( axis=0 ).head() # std ~1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[ \"table_transcriptomics_preprocessed\" ].to_df().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[ \"table_transcriptomics_preprocessed\" ].obs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pct_counts_in_top_2_genes: This column shows the percentage of the total gene expression (count data) in each cell that comes from the top 2 most highly expressed genes in that cell. For example, if 40% of a cell's total gene expression comes from just the top 2 genes, this value would be 40 for that cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sdata[ \"table_transcriptomics\" ].to_df()).sum(axis=1 ).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sdata[ \"table_transcriptomics\" ].to_df() >0 ).sum(axis=1 ).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.pl.preprocess_transcriptomics(\n",
    "    sdata,\n",
    "    table_layer=\"table_transcriptomics_preprocessed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from napari_spatialdata import Interactive\n",
    "\n",
    "#Interactive( sdata )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\",\n",
    "    table_layer=\"table_transcriptomics_preprocessed\",\n",
    "    column=\"total_counts\",\n",
    "    shapes_layer=\"segmentation_mask_boundaries\",\n",
    "    figsize=(8,8)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step you can filter cells based on their size: are you sure cells need to be bigger, or sure your cells can not be larger than X? \n",
    "\n",
    "You can delete them with this function by defining min_size and max_size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = sp.tb.filter_on_size(\n",
    "    sdata,\n",
    "    labels_layer=\"segmentation_mask\",\n",
    "    table_layer=\"table_transcriptomics_preprocessed\",\n",
    "    output_layer=\"table_transcriptomics_filter\",\n",
    "    min_size=500,\n",
    "    max_size=100000,\n",
    "    update_shapes_layers=False,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Clustering\n",
    "\n",
    "This function performs the neighborhood analysis and the leiden clustering and the UMAP calculations using standard scanpy functions.\n",
    "\n",
    "You need to define 2 parameters:\n",
    "- the amount of PC's used: I normally choose something between 15-20 based on the plot of PC's.\n",
    "- The amount of neighbors used: Normally I go for 35. Less neighbors means more spread, more means everything tighter, in general.\n",
    "\n",
    "It returns the UMAP and marker gene list per cluster, that can be looked at for finding celltypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "sdata = sp.tb.leiden(\n",
    "    sdata,\n",
    "    labels_layer=\"segmentation_mask\",\n",
    "    table_layer=\"table_transcriptomics_filter\",\n",
    "    output_layer=\"table_transcriptomics_clustered\",\n",
    "    calculate_umap=True,\n",
    "    calculate_neighbors=True,\n",
    "    n_pcs=17,\n",
    "    n_neighbors=35,\n",
    "    resolution=0.8,\n",
    "    rank_genes=True,\n",
    "    key_added=\"leiden\",\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "sc.pl.umap(sdata.tables[\"table_transcriptomics_clustered\"], color=[\"leiden\"], show=True)\n",
    "sc.pl.rank_genes_groups(sdata.tables[\"table_transcriptomics_clustered\"], n_genes=8, sharey=False, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\",\n",
    "    table_layer=\"table_transcriptomics_clustered\",\n",
    "    column=\"leiden\",\n",
    "    shapes_layer=\"segmentation_mask_boundaries\",\n",
    "    alpha=1.0,\n",
    "    linewidth=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\",\n",
    "    table_layer=\"table_transcriptomics_clustered\",\n",
    "    column=\"leiden\",\n",
    "    shapes_layer=\"segmentation_mask_boundaries\",\n",
    "    alpha=1.0,\n",
    "    linewidth=0,\n",
    "    crd = [ 0, 3000, 1000, 3000 ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for fun, also plot via spatialdataplot\n",
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "column =  \"leiden\"\n",
    "\n",
    "adata = sdata.tables[ \"table_transcriptomics_clustered\" ]\n",
    "\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\n",
    "                    \"new_map\",\n",
    "                    adata.uns[column + \"_colors\"],\n",
    "                    N=len(adata.uns[column + \"_colors\"]),\n",
    "                )\n",
    "\n",
    "sdata_small = sdata.query.bounding_box(\n",
    "    min_coordinate=[0, 1000], max_coordinate=[3000, 3000], axes=(\"x\", \"y\"), target_coordinate_system=\"global\"\n",
    ")\n",
    "\n",
    "sdata_small.pl.render_labels(\"segmentation_mask\", color=column,cmap =cmap, method=\"datashader\", fill_alpha=1).pl.show(\n",
    "    coordinate_systems=\"global\", ax=ax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mg = registry.fetch( \"transcriptomics/resolve/mouse/markerGeneListMartinNoLow.csv\" )\n",
    "\n",
    "sdata, celltypes_scored, celltypes_all = sp.tb.score_genes(\n",
    "    sdata,\n",
    "    labels_layer=\"segmentation_mask\",\n",
    "    table_layer=\"table_transcriptomics_clustered\",\n",
    "    output_layer=\"table_transcriptomics_score_genes\",\n",
    "    path_marker_genes=path_mg,\n",
    "    overwrite=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[ \"table_transcriptomics_score_genes\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "from sparrow.utils._keys import _ANNOTATION_KEY\n",
    "\n",
    "sc.pl.umap(sdata.tables[ \"table_transcriptomics_score_genes\" ], color=_ANNOTATION_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    column=\"annotation\",\n",
    "    img_layer=\"clahe\",\n",
    "    table_layer= \"table_transcriptomics_score_genes\",\n",
    "    shapes_layer=\"segmentation_mask_boundaries\",\n",
    "    linewidth=0,\n",
    "    alpha=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napari_spatialdata import Interactive\n",
    "\n",
    "#Interactive( sdata )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Custom processing on a table layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[ \"table_transcriptomics_score_genes\" ].to_df().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[\"table_transcriptomics_score_genes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import squidpy as sq\n",
    "\n",
    "sq.gr.spatial_neighbors(  sdata[\"table_transcriptomics_score_genes\"] ,coord_type=\"generic\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[\"table_transcriptomics_score_genes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but not yet backed to the zarr store:\n",
    "from spatialdata import read_zarr\n",
    "\n",
    "sdata=read_zarr( sdata.path )\n",
    "sdata[\"table_transcriptomics_score_genes\"]\n",
    "\n",
    "# observe how .uns[ \"spatial_neighbors\" ], .obsp[ \"spatial_connectivities\" ] and .obsp[ \"spatial_distances\" ] are no longer in table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets back the results to the zarr store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparrow.utils._keys import _REGION_KEY\n",
    "\n",
    "sdata[\"table_transcriptomics_score_genes\"].obs[ _REGION_KEY ].cat.categories.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.gr.spatial_neighbors(  sdata[\"table_transcriptomics_score_genes\"] ,coord_type=\"generic\" )\n",
    "\n",
    "sdata = sp.tb.add_table_layer(\n",
    "    sdata,\n",
    "    adata=sdata[\"table_transcriptomics_score_genes\"],\n",
    "    output_layer=\"table_transcriptomics_squidpy\",\n",
    "    region=sdata[\"table_transcriptomics_score_genes\"].obs[ _REGION_KEY ].cat.categories.to_list(),\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[\"table_transcriptomics_squidpy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sdata=sp.tb.nhood_enrichment( sdata, labels_layer=\"segmentation_mask\", table_layer=\"table_transcriptomics_score_genes\", output_layer=\"table_transcriptomics_squidpy\", overwrite=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sp.pl.nhood_enrichment( sdata, table_layer=\"table_transcriptomics_squidpy\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sdata[ \"table_transcriptomics_squidpy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datasets import sdata_resolve\n",
    "\n",
    "#sdata=sdata_resolve( output=\"/Users/arnedf/VIB/DATA/test_data/test.zarr\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "harpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
