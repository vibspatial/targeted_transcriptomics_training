{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harpy pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import harpy as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in the data\n",
    "\n",
    "In this notebook, we will be working with a Resolve Biosciences Molecular Cartography dataset of a mouse liver WT sample. The dataset will be downloaded and cached using `pooch` via `harpy.dataset.registry`. \n",
    "\n",
    "The DAPI image is then read in using the `bioio` package (see https://bioio-devs.github.io/bioio/) and added to a `SpatialData` object (see https://spatialdata.scverse.org/en/latest/ for more information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from harpy.datasets.registry import get_registry\n",
    "\n",
    "unit_testing = True\n",
    "\n",
    "# The dataset will downloaded from the registry. If path is set to None, example data will be downloaded in the default cache folder of your os. Change path to your directory of choice to overwrite this behaviour.\n",
    "registry = get_registry(path = None) # on Windows, set path (e.g. to r\"c:\\tmp\")\n",
    "path_image = registry.fetch(\"transcriptomics/resolve/mouse/20272_slide1_A1-1_DAPI.tiff\")\n",
    "path_coordinates = registry.fetch(\"transcriptomics/resolve/mouse/20272_slide1_A1-1_results.txt\")\n",
    "\n",
    "# The OUTPUT_DIR is the directory where the SpatialData .zarr will be saved. Change it to your output directory of choice.\n",
    "OUTPUT_DIR =  tempfile.gettempdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioio import BioImage\n",
    "\n",
    "# The DAPI image is read using bioio\n",
    "img = BioImage(path_image)\n",
    "\n",
    "# We print the image dimensions\n",
    "print('Image dimensions: ', img.dims)\n",
    "\n",
    "# We can have a look at the dask array\n",
    "img.dask_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We \"squeeze\" the data to collapse the T and Z dimensions\n",
    "array = img.dask_data.squeeze((0, 2)) # Squeeze T and Z dimension\n",
    "\n",
    "# Let's look at the new dask array\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "from spatialdata import SpatialData, read_zarr\n",
    "\n",
    "# Create an empty SpatialData object\n",
    "sdata = SpatialData()\n",
    "\n",
    "# Set the path for the SpatialData .zarr\n",
    "zarr_path = os.path.join(OUTPUT_DIR, f\"sdata_{uuid.uuid4()}.zarr\")\n",
    "\n",
    "# Write the SpatialData to Zarr\n",
    "sdata.write(zarr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the Zarr data back as a SpatialData\n",
    "sdata = read_zarr(sdata.path)\n",
    "\n",
    "# Check if SpatialData is backed (i.e. stored on disk)\n",
    "sdata.is_backed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add the DAPI image to the SpatialData object\n",
    "sdata = hp.im.add_image_layer(\n",
    "    sdata, # The SpatialData object to which the new image layer will be added.\n",
    "    arr = array, # The array containing the image data to be added.\n",
    "    dims = ( \"c\", \"y\", \"x\" ), # A tuple specifying the dimensions of the image data\n",
    "    output_layer = \"raw_image\", # The name of the output layer where the image data will be stored.\n",
    "    overwrite = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can access the DAPI image like this:\n",
    "sdata[\"raw_image\"] # Or, alternatively: sdata.images[\"raw_image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a crop of the DAPI image\n",
    "hp.pl.plot_image(\n",
    "    sdata, \n",
    "    img_layer = \"raw_image\" , \n",
    "    crd = [0, 6432, 0, 6432], # The coordinates for the region of interest in the format (xmin, xmax, ymin, ymax). If None, the entire image is plotted.\n",
    "    figsize = (5,5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or, alternatively, via spatialdata-plot:\n",
    "import spatialdata_plot\n",
    "sdata.pl.render_images(\"raw_image\").pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Use the `Harpy` function `hp.pl.plot_shapes` to visualize another crop (e.g.: `x_min=2000`, `x_max=4000`, `y_min=1000`, `y_max=4000`). \n",
    "\n",
    "- Bonus: How would you save the plot to disk?\n",
    "\n",
    "- Bonus: Read the docstring of `hp.pl.plot_shapes`. What does the `fig_kwargs` parameter do? Can you change `dpi` of the resulting image?\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "hp.pl.plot_shapes( sdata, img_layer=\"raw_image\", crd = [ 2000, 4000, 1000, 4000 ], output = f'{OUTPUT_DIR}/plot.png', fig_kwargs={ \"dpi\":300 } )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Uncomment the following cell and explore the DAPI image in Napari. Try changing the contrast of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from napari_spatialdata import Interactive\n",
    "\n",
    "# Interactive(sdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "- Bonus: Add DAPI as a multiscale image to the SpatialData object (tip: read the documentation).\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "# Add as multiscale image\n",
    "sdata=hp.im.add_image_layer(\n",
    "    sdata,\n",
    "    arr = array,\n",
    "    dims = ( \"c\", \"y\", \"x\" ),\n",
    "    output_layer = \"raw_image\",\n",
    "    scale_factors = [2, 2, 2, 2],\n",
    "    overwrite = True,\n",
    ")\n",
    "\n",
    "# Now it is a DataTree\n",
    "type(sdata[\"raw_image\"])  \n",
    "\n",
    "# Let's have a look at the dask array\n",
    "from harpy.image._image import _get_spatial_element\n",
    "se = _get_spatial_element(sdata, layer=\"raw_image\")\n",
    "se.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image preprocessing\n",
    "\n",
    "### 2.1 tiling correction and inpainting\n",
    "\n",
    "When working with RESOLVE data, the data is acquired in tiles that have uneven illumination and this can influence the downstream analysis greatly. RESOLVE assured us this shouldn't impact the transcript counts, but we can check later on whether this is the case. This step is not necessary for most other imaging-based spatial transcriptomics technologies (Xenium, Merscope, ...), but you should plot the entire image to check whether you need this preprocessing step for your data. \n",
    "\n",
    "Harpy's tiling_correction() function can be used to correct for uneven illumination (using BaSiC on the back-end). The size of the imaging tiles needs to be known in order to run the function. The tile_size parameter is set to the tile size of RESOLVE (2144) by default.\n",
    "\n",
    "The tiling_correction() function also corrects for the black lines in between the tiles by using OpenCV's inpainting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing tiling correction\n",
    "sdata, flatfields = hp.im.tiling_correction(\n",
    "    sdata = sdata,\n",
    "    img_layer = \"raw_image\",\n",
    "    tile_size = 2144, # This is set to 2144 by default\n",
    "    output_layer = \"tiling_correction\",\n",
    "    crd = [0, 6432, 0, 6432],\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the raw and corrected image side-by-side\n",
    "hp.pl.plot_image(sdata, img_layer=[ \"raw_image\", \"tiling_correction\" ], crd =  [2000, 6000, 2000, 6000], figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 min-max filtering and contrast enhancing\n",
    "The next preprocessing steps include:\n",
    "\n",
    "- A min max filter can be added. The goal of this function is to substract background noise and make the borders of the nuclei/cells cleaner. It will also remove some debris. Note that if you set the size of the filter too small (smaller then the size of your nuclei), the function will create \"donuts\" (black spots in the center of your cells). If the size of the min max filter is chosen too big, not enough background will be subtracted. Generally, you want to aim for the average nucleus size and some fine-tuning may be necessary. For nuclei in RESOLVE data, 45-55 should be a great starting point.\n",
    "\n",
    "- We also recommend to perform contrast enhancement on your image. Harpy does this by using histogram equalization (CLAHE function). The amount of correction needed can be decided by adapting the contrast_clip value. If the image is already quite bright, 3.5 might be a good starting point. For dark images, you can go up to 10 or even more. Make sure at the end the whole image is evenly illuminated and no cells are dark in the background.\n",
    " \n",
    "If you think your data needs further image processing steps, you can perform these using the map_image function (see further)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform min max filtering\n",
    "sdata = hp.im.min_max_filtering(\n",
    "    sdata,\n",
    "    img_layer = \"tiling_correction\",\n",
    "    output_layer = \"min_max_filtered\",\n",
    "    size_min_max_filter = 45,\n",
    "    overwrite = True,\n",
    ")\n",
    "\n",
    "# Plot the min max filtered image\n",
    "hp.pl.plot_image(\n",
    "    sdata,\n",
    "    img_layer = \"min_max_filtered\",\n",
    "    crd = [2000,6000,2000,6000],\n",
    "    figsize = (5, 5),\n",
    ")\n",
    "\n",
    "# Perform contrast enhancement using CLAHE\n",
    "sdata = hp.im.enhance_contrast(\n",
    "    sdata,\n",
    "    img_layer = \"min_max_filtered\",\n",
    "    output_layer = \"clahe\",\n",
    "    contrast_clip = 3.5,\n",
    "    chunks = 20000,\n",
    "    overwrite = True\n",
    ")\n",
    "\n",
    "# Plot the contrast enhanced image\n",
    "hp.pl.plot_image(\n",
    "    sdata,\n",
    "    img_layer = \"clahe\",\n",
    "    crd = [2000,6000,2000,6000],\n",
    "    figsize = (5, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Change the `size_min_max_filter` parameter in `hp.im.min_max_filtering`. What do you see? Try some extreme values.\n",
    "- Change the `enhance_contrast` parameter in `hp.im.enhance_contrast`. What do you see? Try some extreme values.\n",
    "- Try image preprocessing on a different crop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Uncomment the following cell and explore the preprocessed images in Napari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interactive(sdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Custom distributed preprocessing of images using `hp.im.map_image` and `Dask`\n",
    "\n",
    "See https://docs.dask.org/en/stable/generated/dask.array.map_blocks.html and https://docs.dask.org/en/latest/generated/dask.array.map_overlap.html\n",
    "\n",
    "Set `blockwise==True` if you want to do distributed processing using `dask.array.map_blocks` or `dask.array.map_overlap`, set `blockwise==False` if your function is already distributed (e.g. when using `dask_image` filters https://image.dask.org/en/latest/dask_image.ndfilters.html.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "# Define your custom function\n",
    "def _my_dummy_function(image: NDArray, parameter: int | float )->NDArray:\n",
    "    # input (1,1,y,x)\n",
    "    # output (1,1,y,x)\n",
    "    print(f\"Type of the image is: {type(image)}\")\n",
    "    print(image.shape)\n",
    "    return image*parameter\n",
    "\n",
    "fn_kwargs = {\"parameter\": 2}\n",
    "\n",
    "# Apply custom function\n",
    "sdata = hp.im.map_image(\n",
    "    sdata,\n",
    "    func = _my_dummy_function,\n",
    "    fn_kwargs = fn_kwargs,\n",
    "    img_layer = \"raw_image\",\n",
    "    output_layer=\"dummy_image\",\n",
    "    chunks = 5000,\n",
    "    blockwise = True, # if blockwise == True --> input to _my_dummy_function is a numpy array of size chunks, else it is a Dask array (with chunksize chunks)\n",
    "    depth = 1000, # if blockwise == True, and depth specified, will use map_overlap instead of map_blocks for distributed processing\n",
    "    overwrite = True,\n",
    "    dtype = np.uint16,\n",
    "    meta = np.array((), dtype=np.uint16),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from harpy.image._image import _get_spatial_element\n",
    "\n",
    "_get_spatial_element(sdata, layer=\"raw_image\").data.compute()[ :, :10, :10 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_get_spatial_element(sdata, layer=\"dummy_image\").data.compute()[ :, :10,:10 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Adapt `my_dummy_function` so it accepts a new parameter, `parameter_2`. Now adapt `my_dummy_function` so the image is multiplied with (`parameter` + `parameter_2`)\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "def _my_dummy_function(image: NDArray, parameter: int | float, parameter_2: int | float )->NDArray:\n",
    "    # input (1,1,y,x)\n",
    "    # output (1,1,y,x)\n",
    "    print(f\"Type of the image is: {type(image)}\" )\n",
    "    print(image.shape)\n",
    "    return image*(parameter + parameter_2)\n",
    "\n",
    "fn_kwargs = {\"parameter\": 2 , \"parameter_2\": 2}\n",
    "\n",
    "sdata = hp.im.map_image(\n",
    "    sdata,\n",
    "    func = _my_dummy_function,\n",
    "    fn_kwargs = fn_kwargs,\n",
    "    img_layer = \"raw_image\",\n",
    "    output_layer=\"dummy_image\",\n",
    "    chunks = 5000,\n",
    "    blockwise = True, # if blockwise == True --> input to _my_dummy_function is a numpy array of size chunks, else it is a Dask array (with chunksize chunks)\n",
    "    depth = 1000, # if blockwise == True, and depth specified, will use map_overlap instead of map_blocks for distributed processing\n",
    "    overwrite = True,\n",
    "    dtype = np.uint16,\n",
    "    meta = np.array((), dtype=np.uint16),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Bonus: Run the cell where `hp.im.map_image` is called in debug mode. Set a breakpoint in `my_dummy_function`. Inspect the shape and type of `image` when you set `blockwise=True` or `blockwise=False`. Set the `depth` parameter to `100`. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Segmentation\n",
    "\n",
    "### 3.1 Nucleus segmentation\n",
    "\n",
    "To segment the nuclei, we here show an example using cellpose, a deep learning network based on a UNET architecture.\n",
    "\n",
    "Multiple parameters need to be given as an input to the cellpose algorithm. We recommend tuning these to achieve optimal segmentation quality (see https://cellpose.readthedocs.io/en/latest/settings.html). It is often a good idea to fine-tune the parameters on a crop of the image (especially when you only have CPU to work with).\n",
    " \n",
    "- diameter: Includes an estimate of the average nucleus diameter and needs to be given in pixels. If set to None, cellpose will try to estimate the diameter, but this might take a long time and is usually far off. As a guideline, you can use approx. 7 micrometer (in this case 50 pixels at 0.138 micrometer per pixel) for a standard nucleus, but this may vary depending on your specific tissue, sample...\n",
    "- device: Defines the device you want to work on. If you only have CPU, you can skip this input parameter.\n",
    "- flow_threshold: Indicates something about the shape of the masks. If you increase it, more masks with less round shapes will be accepted. Usually set between 0.6 and 0.95 (max. is 1). Lower this parameter if you start segmenting artefacts. Increase it if the segmentation misses some non-round cells.\n",
    "- mask_threshold: Indicates how many of the possible masks are kept. Decreasing the parameter will output more masks. Larger values will output less masks. Usually set between 0 and -6.\n",
    "- min_size: Indicates the minimum size of a nucleus.\n",
    "- model_type: If segmenting whole cells instead of nuclei, set this to 'cyto'. You can do this with and without a nucleus channel. When you want to include a nucleus channel for the segmentation, make sure your image is 3D and that the first channel contains the complete cell staining and the second one the nucleus channel (put the channel parameter to np.array([1,0]))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ADVANCED: You can set up a local Dask distributed cluster for parallel computing. Once the cluster is created, a Dask Client is used to connect to it. \n",
    "The Dask dashboard link allows you to monitor cluster performance and task progress.\n",
    "\"\"\"\n",
    "\n",
    "# from dask.distributed import Client, LocalCluster\n",
    "\n",
    "# # Create a local Dask cluster\n",
    "# cluster = LocalCluster(\n",
    "#     n_workers=1,              # Number of worker processes\n",
    "#     threads_per_worker=10,    # Number of threads per worker\n",
    "#     memory_limit=\"32GB\",      # Memory limit per worker\n",
    "# )\n",
    "\n",
    "# # Connect a Client to the cluster\n",
    "# client = Client(cluster)\n",
    "\n",
    "# # Print the Dask dashboard link\n",
    "# print(client.dashboard_link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from cellpose import models\n",
    "from harpy.image import cellpose_callable\n",
    "\n",
    "gpu = False\n",
    "device = \"cpu\"  # mps broken in cellpose (macOS), see https://github.com/MouseLand/cellpose/issues/1063\n",
    "model = models.CellposeModel(gpu=gpu, pretrained_model='nuclei', device = torch.device(device))\n",
    "\n",
    "# model = client.scatter(model) # ADVANCED: Uncomment this when using the Dask Client. We pass a loaded model to _cellpose, but we scatter the model to avoid large task graph.\n",
    "\n",
    "# Perform nucleus segmentation\n",
    "sdata = hp.im.segment(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\", # The image layer in sdata to be segmented.\n",
    "    chunks=2048,\n",
    "    depth=200,\n",
    "    model=cellpose_callable,\n",
    "    # parameters that will be passed to the callable _cellpose:\n",
    "    pretrained_model=model,\n",
    "    diameter=50,\n",
    "    flow_threshold=0.9,\n",
    "    cellprob_threshold=-4,\n",
    "    output_labels_layer=\"segmentation_mask\",\n",
    "    output_shapes_layer=\"segmentation_mask_boundaries\",\n",
    "    crd=[2000, 4000, 2000, 4000] if unit_testing else None,  # region to segment [x_min, xmax, y_min, y_max],\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "#client.close() # ADVANCED: Uncomment this when using the Dask Client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot segmentation results\n",
    "hp.pl.plot_shapes(sdata, img_layer=\"clahe\", shapes_layer=\"segmentation_mask_boundaries\", figsize=(5,5), crd = [2000, 4000, 2000, 4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or via spatialdata-plot\n",
    "sdata.pl.render_images(\"clahe\").pl.render_labels(\"segmentation_mask\").pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To only visualize a crop using spatialdata-plot, we can't pass any coordinates, so but we can perform a bounding box query, and then plot the resulting `SpatialData` object.\n",
    "sdata_small = sdata.query.bounding_box(\n",
    "    min_coordinate=[2000, 2000], max_coordinate=[4000, 4000], axes=(\"x\", \"y\"), target_coordinate_system=\"global\"\n",
    ")\n",
    "\n",
    "sdata_small.pl.render_images(\"clahe\").pl.render_labels(\"segmentation_mask\", fill_alpha=0.5  ).pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Try changing segmentation parameters to see how they affect the results.\n",
    "- Go to the [documentation](https://spatialdata.scverse.org/projects/plot/en/latest/) of `spatialdata-plot`, and try to visualize the cell boundaries (i.e. the segmentation shapes layer)\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "sdata_small.pl.render_images(\"clahe\").pl.render_shapes(\"segmentation_mask_boundaries\", fill_alpha=1.0).pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Nucleus expansion\n",
    "In some cases, it may be useful to expand de nuclei segmentations to approximate the cell bodies. Note that this is not very precise and, while it increases the number of transcripts assigned to a cell, it also introduces more wrongly assigned transcripts (i.e. that actually belong to other cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand labels layer masks\n",
    "sdata = hp.im.expand_labels_layer(\n",
    "    sdata,\n",
    "    labels_layer=\"segmentation_mask\",\n",
    "    distance=10, # Number of pixels to expand\n",
    "    output_labels_layer=\"segmentation_mask_expanded\", # Creates a new labels layer\n",
    "    output_shapes_layer=\"segmentation_mask_expanded_boundaries\", # Creates a new shapes layer\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot nuclei masks vs expanded nuclei masks\n",
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\",\n",
    "    shapes_layer=[\"segmentation_mask_boundaries\", \"segmentation_mask_expanded_boundaries\"],\n",
    "    figsize=(10,10),\n",
    "    crd=[2000, 4000, 2000, 4000],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Allocating  the transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4.1 Creating the count matrix\n",
    "In this step we\n",
    "- load in the transcipts: in the case of RESOLVE this is done with a specific loader. If no specific loader exist for your datatype, you can use the general `hp.io.read_transcripts` function.\n",
    "- allocate the transcripts to the correct cell. This allocation step creates the count matrix saved in an [anndata](https://anndata.readthedocs.io/en/stable/) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in RESOLVE transcript data as a points layer\n",
    "sdata = hp.io.read_resolve_transcripts(\n",
    "    sdata, \n",
    "    output_layer=\"transcripts\", # Name of the points layer of the SpatialData object to which the transcripts will be added.\n",
    "    path_count_matrix=path_coordinates, # Path to the file containing the transcripts information specific to Resolve.\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# Allocate transcripts to cells based on the segmentation masks\n",
    "sdata = hp.tb.allocate(\n",
    "    sdata=sdata,\n",
    "    labels_layer=\"segmentation_mask\", # The labels layer (i.e. segmentation mask) in `sdata` to be used to allocate the transcripts to cells.\n",
    "    points_layer=\"transcripts\", # The points layer in `sdata` that contains the transcripts.\n",
    "    output_layer=\"table_transcriptomics\", # The table layer in `sdata` in which to save the AnnData object with the transcripts counts per cell.\n",
    "    update_shapes_layers=False,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the new points layer\n",
    "print(type(sdata.points[\"transcripts\"]))\n",
    "sdata.points[\"transcripts\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the new table layer\n",
    "display(sdata.tables[\"table_transcriptomics\"])\n",
    "\n",
    "print('Number of cells: ', len(sdata.tables[\"table_transcriptomics\"].obs.index))\n",
    "print('Number of genes: ', len(sdata.tables[\"table_transcriptomics\"].var.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the count matrix in the new table layer\n",
    "sdata.tables[\"table_transcriptomics\"].to_df().head() # On large count matrices, calls to .to_df() should be avoided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the var of the new table layer\n",
    "sdata.tables[\"table_transcriptomics\"].var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the obs of the new table layer\n",
    "sdata.tables[\"table_transcriptomics\"].obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the spatial coordinates stored in obsm\n",
    "sdata.tables[\"table_transcriptomics\"].obsm['spatial'][:5] # x,y,(z) coordinates of cell centre (calculated based on mean transcripts location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the spatialdata_attrs in .uns to check the instance_key and region_key\n",
    "sdata.tables[\"table_transcriptomics\"].uns['spatialdata_attrs']\n",
    "\n",
    "# NOTE: The AnnData object that is added as a table layer is annotated by the labels layer \"segmentation_mask\". The instance_key ('cell_ID') matches the labels in \"segmentation_mask\".\n",
    "# NOTE: Tables of a SpatialData object can be theoretically be annotated by a labels layer, a shapes layer or a points layer, but tables generated by the Harpy pipeline will always use a labels layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "print('Number of cells in table: ', len(sdata.tables[\"table_transcriptomics\"].obs))\n",
    "print('Number of segmentation masks in labels layer: ', len(da.unique(sdata.labels[\"segmentation_mask\"].data).compute()) - 1) # We subtract 1 because 0 is also a value, but this corresponds to the background.\n",
    "print('Number of segmentation boundaries in shapes layer: ', len(sdata.shapes[\"segmentation_mask_boundaries\"]))\n",
    "\n",
    "# NOTE: Not all segmentation masks are included in the table layer \"table_transcriptomics\". This is because not all cells could be assigned transcripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Run .compute() on the points layer. What is the data type of the resulting object?\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "from IPython.display import display\n",
    "\n",
    "display(sdata[\"transcripts\"].compute().head())\n",
    "display(type(sdata[\"transcripts\"].compute())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Have a look at https://docs.dask.org/en/stable/dataframe.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Bonus: Extract transformation from the points layer \"transcripts\" using `spatialdata.transformations.get_transformation`. See https://spatialdata.scverse.org/en/stable/generated/spatialdata.transformations.get_transformation.html\n",
    "- Bonus: Now extract the transformation from the labels layer \"segmentation_mask\" and for the image layer \"clahe\".\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "from IPython.display import display\n",
    "from spatialdata.transformations import get_transformation\n",
    "\n",
    "display(get_transformation(sdata[\"transcripts\"]))\n",
    "display(get_transformation(sdata[\"segmentation_mask\"]))\n",
    "display(get_transformation(sdata[\"clahe\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Visualize the points layer and the labels layer using napari-spatialdata. Convince yourself they are registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive(sdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Visualizing gene expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the expression of the Axl gene using hp.pl.polt_shapes()\n",
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\",\n",
    "    shapes_layer=\"segmentation_mask_boundaries\",\n",
    "    figsize=(5,5),\n",
    "    crd=[2000, 4000, 2000, 4000],\n",
    "    table_layer=\"table_transcriptomics\",\n",
    "    column=\"Axl\",\n",
    ")\n",
    "\n",
    "# NOTE: In Harpy/SpatialData there is a connection between tables, shapes and labels via the region_key and the cell id, which allows us to plot a certain column of a table spatially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the expression of the Axl gene using spatialdata-plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "gene_name = \"Axl\"\n",
    "sdata.pl.render_labels(\"segmentation_mask\", color=gene_name, method=\"datashader\", fill_alpha=0.5).pl.show(\n",
    "    coordinate_systems=\"global\", ax=ax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore gene expression interactively using napari-spatialdata\n",
    "\n",
    "#Interactive(sdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Use `hp.pl.plot_shapes` to plot the expression of some other genes that are in the dataset.\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "display(sdata[\"table_transcriptomics\"].var)\n",
    "\n",
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\",\n",
    "    shapes_layer=\"segmentation_mask_boundaries\",\n",
    "    figsize=(5,5),\n",
    "    crd=[2000, 4000, 2000, 4000],\n",
    "    table_layer=\"table_transcriptomics\",\n",
    "    column=\"Vwf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "Use `napari-spatialdata` to visualize the gene expression of the gene `Axl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive(sdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4.3 Transcript quality\n",
    "After we have created the anndata object, we want to check the transcript quality. First we create a plot to check if the transcript density is similar across the whole tissue. If this isn't the case, there can be multiple biological or technical reasons. Note that gene panel choices can also have an influence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transcript density image\n",
    "sdata = hp.im.transcript_density(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\", # The layer of the SpatialData object used for determining image boundary.\n",
    "    points_layer=\"transcripts\", # The layer name that contains the transcript data points, by default \"transcripts\".\n",
    "    output_layer=\"transcript_density\", # The name of the output image layer\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot transcript density\n",
    "hp.pl.plot_image(sdata, img_layer = [\"clahe\", \"transcript_density\"], figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of transcripts\n",
    "print('Number of transcripts in points layer: ', len(sdata.points[\"transcripts\"]))\n",
    "print('Number of transcripts assigned to cells: ', sdata.tables[\"table_transcriptomics\"].X.sum())\n",
    "print('Percentage of transcripts kept: ', ((sdata.tables[\"table_transcriptomics\"].X.sum())/len(sdata.points[\"transcripts\"]))*100)\n",
    "\n",
    "# NOTE: Only a fraction of transcripts are assigned to cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of genes\n",
    "print('Number of genes in points layer: ', sdata.points['transcripts'].compute()['gene'].nunique())\n",
    "print('Number of genes found in cells: ', len(sdata.tables[\"table_transcriptomics\"].var.index))\n",
    "\n",
    "# NOTE: In general, we don't want to lose any genes, but this may happen if they have a low abundance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which genes are not found in cells\n",
    "genes_not_found_in_cells = set(sdata.points['transcripts'].compute()['gene'].unique()) - set(sdata.tables[\"table_transcriptomics\"].var.index)\n",
    "\n",
    "print(\"Number of genes not found in cells: \", len(genes_not_found_in_cells))\n",
    "print(\"Genes not found in cells:\", genes_not_found_in_cells)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse and visualize the proportion of transcripts that could not be assigned to a cell during allocation step.\n",
    "\n",
    "df = hp.pl.analyse_genes_left_out(\n",
    "    sdata,\n",
    "    labels_layer=\"segmentation_mask\",\n",
    "    table_layer=\"table_transcriptomics\",\n",
    "    points_layer=\"transcripts\",\n",
    ")\n",
    "\n",
    "# NOTE: In general we see a downward trend. The more a gene is measured, the less it is located in cells (in ratio). \n",
    "# NOTE: The function also prints the ten genes with the highest proportion of transcripts filtered out. If a lot of these genes are markers for the same cell type, you will want to find out why this is happening (bad staining, large cell body compared to nucleus, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect analyse_genes_left_out() output table\n",
    "df.sort_values(by=\"proportion_kept\", ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Processing the AnnData table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Filtering and Normalization\n",
    "\n",
    "The next steps are performed to further process the AnnData object:\n",
    "\n",
    "- QC metrics are calculated.\n",
    "- Filtering: cells with fewer than a certain amount of counts (e.g. 10) and genes occuring in fewer than a certain amount of cells (e.g. 5) are filtered out.\n",
    "- Normalization: for small gene panels (<500), we recommend to normalize the data based on the size of the segmented object (`size_norm=True`). For transcriptome-wide methods, we recommend library size normalization based on the total expression (`size_norm=False`). \n",
    "- log1p-transformation of the expression data (y=ln(1+x)).\n",
    "- Scale data to unit variance and zero mean. The scaling is capped at `max_value_scale`.\n",
    "- PCA calculation\n",
    "\n",
    "\n",
    "The last plot shows the size of the nucleus related to the counts. When working with whole cells, if there are some really big cells with really low counts, they are probably not real cells and you should filter based on max size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform preprocessing.\n",
    "sdata = hp.tb.preprocess_transcriptomics(\n",
    "    sdata,\n",
    "    labels_layer=\"segmentation_mask\",\n",
    "    table_layer=\"table_transcriptomics\",\n",
    "    output_layer=\"table_transcriptomics_preprocessed\", # write results to a new slot, we could also write to the same slot (when passing overwrite==True).\n",
    "    min_counts=10,\n",
    "    min_cells=5,\n",
    "    size_norm=True,\n",
    "    highly_variable_genes=False,  # If True, will only retain highly variable genes. This can be used for transcriptome-wide methods.\n",
    "    max_value_scale=10, # The maximum value to which data will be scaled\n",
    "    n_comps=50, # Number of principal components to calculate.\n",
    "    overwrite=True,\n",
    "    update_shapes_layers=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect preprocessed table\n",
    "sdata.tables[ \"table_transcriptomics_preprocessed\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect expression values\n",
    "sdata.tables[\"table_transcriptomics_preprocessed\"].to_df().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check mean expression values per gene\n",
    "sdata.tables[\"table_transcriptomics_preprocessed\"].to_df().mean(axis=0).head() # mean ~ 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check standard deviation of expression values per gene\n",
    "sdata.tables[\"table_transcriptomics_preprocessed\"].to_df().std(axis=0).head() # std ~ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check max expression value per gene\n",
    "sdata.tables[\"table_transcriptomics_preprocessed\"].to_df().max(axis=0).head() # max ~ 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect obs of preprocessed table\n",
    "sdata.tables[\"table_transcriptomics_preprocessed\"].obs.head()\n",
    "\n",
    "# n_genes_by_counts: The number of genes with at least 1 count in a cell\n",
    "# log1p_n_genes_by_counts: log1p-transformed n_genes_by_counts\n",
    "# total_counts: Total number of counts for a cell\n",
    "# log1p_total_counts: log1p-transformed total_counts\n",
    "# pct_counts_in_top_2_genes: The percentage of the total gene expression in each cell that comes from the top 2 most highly expressed genes in that cell\n",
    "# pct_counts_in_top_5_genes: The percentage of the total gene expression in each cell that comes from the top 5 most highly expressed genes in that cell \n",
    "# n_counts: Number of counts in a cell\n",
    "# shapeSize: Area of cell (in pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sum of transcript counts\n",
    "(sdata.tables[\"table_transcriptomics\"].to_df()).sum(axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of genes\n",
    "(sdata.tables[\"table_transcriptomics\"].to_df()>0).sum(axis = 1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect var of preprocessed table\n",
    "sdata.tables[\"table_transcriptomics_preprocessed\"].var.head()\n",
    "\n",
    "# n_cells_by_counts: Number of cells this gene is found in\n",
    "# mean_counts: Mean counts over all cells\n",
    "# log1p_mean_counts: log1p of mean_counts\n",
    "# pct_drop_by_counts: Percentage of cells this gene does not appear in\n",
    "# total_counts: Total number of counts for a gene\n",
    "# logp_total_counts: log1p of total_counts\n",
    "# n_cells: Number of cells this gene is found in\n",
    "# mean:\n",
    "# std:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot preprocessing QC plots\n",
    "hp.pl.preprocess_transcriptomics(\n",
    "    sdata,\n",
    "    table_layer=\"table_transcriptomics_preprocessed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot total counts\n",
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\",\n",
    "    table_layer=\"table_transcriptomics_preprocessed\",\n",
    "    column=\"total_counts\",\n",
    "    shapes_layer=\"segmentation_mask_boundaries\",\n",
    "    crd=[2000, 4000, 2000, 4000],\n",
    "    figsize=(8,8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter cells on size\n",
    "sdata = hp.tb.filter_on_size(\n",
    "    sdata,\n",
    "    labels_layer=\"segmentation_mask\",\n",
    "    table_layer=\"table_transcriptomics_preprocessed\",\n",
    "    output_layer=\"table_transcriptomics_filter\",\n",
    "    min_size=500, # Minimum cell size\n",
    "    max_size=100000, # Maximum cell size\n",
    "    update_shapes_layers=False,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which cells have been removed\n",
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\",\n",
    "    table_layer=\"table_transcriptomics_filter\",\n",
    "    column=\"total_counts\",\n",
    "    shapes_layer=\"segmentation_mask_boundaries\",\n",
    "    crd=[2000, 4000, 2000, 4000],\n",
    "    figsize=(8,8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore results interactively\n",
    "\n",
    "#Interactive( sdata )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Clustering\n",
    "\n",
    "This function performs the neighborhood analysis and the leiden clustering and the UMAP calculations using standard scanpy functions.\n",
    "\n",
    "You need to define the following parameters:\n",
    "- The amount of PC's used: Between 15-20 is a good starting point (based on the plot of PCs).\n",
    "- The amount of neighbors used: 35 is generally a good value. In general, less neighbors means more spread, more means everything is tighter.\n",
    "- Cluster resolution.\n",
    "\n",
    "It returns the UMAP and marker gene list per cluster, that can be looked at for finding celltypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "# Leiden clustering\n",
    "sdata = hp.tb.leiden(\n",
    "    sdata,\n",
    "    labels_layer=\"segmentation_mask\",\n",
    "    table_layer=\"table_transcriptomics_filter\",\n",
    "    output_layer=\"table_transcriptomics_clustered\",\n",
    "    calculate_umap=True,\n",
    "    calculate_neighbors=True,\n",
    "    n_pcs=17, # The number of principal components to use when calculating neighbors.\n",
    "    n_neighbors=35, # The number of neighbors to consider when calculating neighbors.\n",
    "    resolution=0.8,\n",
    "    rank_genes=True,\n",
    "    key_added=\"leiden\",\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# Plot UMAP\n",
    "sc.pl.umap(sdata.tables[\"table_transcriptomics_clustered\"], color=[\"leiden\"], show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.rank_genes_groups(sdata.tables[\"table_transcriptomics_clustered\"], n_genes=8, sharey=False, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot clusters spatially\n",
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\",\n",
    "    table_layer=\"table_transcriptomics_clustered\",\n",
    "    column=\"leiden\",\n",
    "    shapes_layer=\"segmentation_mask_boundaries\",\n",
    "    alpha=1.0,\n",
    "    linewidth=0,\n",
    "    crd=[2000, 4000, 2000, 4000]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "Change the parameters of `hp.tb.leiden`. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from napari_spatialdata import Interactive\n",
    "\n",
    "#del sdata.tables[\"table_transcriptomics_clustered\"].uns[\"leiden_colors\"]\n",
    "#Interactive(sdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for fun, also plot via spatialdataplot\n",
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "column = \"leiden\"\n",
    "\n",
    "adata = sdata.tables[ \"table_transcriptomics_clustered\" ]\n",
    "\n",
    "#cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\n",
    "#                    \"new_map\",\n",
    "#                    adata.uns[column + \"_colors\"],\n",
    "#                    N=len(adata.uns[column + \"_colors\"]),\n",
    "#                )\n",
    "\n",
    "sdata_small = sdata.query.bounding_box(\n",
    "    min_coordinate=[2000, 2000], max_coordinate=[4000, 4000], axes=(\"x\", \"y\"), target_coordinate_system=\"global\"\n",
    ")\n",
    "\n",
    "sdata_small.pl.render_labels(\"segmentation_mask\", color=column, cmap=None, method=\"datashader\", fill_alpha=1).pl.show(\n",
    "    coordinate_systems=\"global\", ax=ax\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Cell type annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use a marker gene list and score cells for each cell type using those markers via scanpy's `sc.tl.score_genes` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Download annotation file from registry\n",
    "path_mg = registry.fetch(\"transcriptomics/resolve/mouse/markerGeneListMartinNoLow.csv\")\n",
    "\n",
    "# Inspect annotation file containing markers\n",
    "display(pd.read_csv(path_mg).head()) # This is one-hot encoded matrix with cell types listed in the first row, and marker genes in the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate cells\n",
    "sdata, celltypes_scored, celltypes_all = hp.tb.score_genes(\n",
    "    sdata,\n",
    "    labels_layer=\"segmentation_mask\",\n",
    "    table_layer=\"table_transcriptomics_clustered\",\n",
    "    output_layer=\"table_transcriptomics_score_genes\",\n",
    "    path_marker_genes=path_mg, # Path to annotation file\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect new table layer\n",
    "sdata[\"table_transcriptomics_score_genes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect new table layer obs\n",
    "sdata.tables[\"table_transcriptomics_score_genes\"].obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cell type annotations on UMAP\n",
    "sc.pl.umap(sdata.tables[\"table_transcriptomics_score_genes\"], color=\"annotation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cell type annotations spatially\n",
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    column=\"annotation\",\n",
    "    img_layer=\"clahe\",\n",
    "    table_layer= \"table_transcriptomics_score_genes\",\n",
    "    shapes_layer=\"segmentation_mask_boundaries\",\n",
    "    linewidth=0,\n",
    "    alpha=0.7,\n",
    "    crd=[2000, 4000, 2000, 4000]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Squidpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try calculating spatial neighbors using Squidpy\n",
    "import squidpy as sq\n",
    "\n",
    "sq.gr.spatial_neighbors(\n",
    "    adata=sdata[\"table_transcriptomics_score_genes\"], \n",
    "    coord_type=\"generic\", # Set to 'generic' for targeted spatial transcriptomics\n",
    "    n_neighs=6, # Only used when delaunay = False\n",
    "    radius=None, # To compute the neighbors based on the radius\n",
    "    delaunay=False, # Whether to compute the graph from Delaunay triangulation\n",
    ")\n",
    "\n",
    "sdata.tables[\"table_transcriptomics_score_genes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUT, this is not yet backed to the zarr store!\n",
    "from spatialdata import read_zarr\n",
    "\n",
    "sdata = read_zarr(sdata.path)\n",
    "\n",
    "sdata.tables[\"table_transcriptomics_score_genes\"]\n",
    "\n",
    "# NOTE: .uns[\"spatial_neighbors\"], .obsp[\"spatial_connectivities\"] and .obsp[\"spatial_distances\"] are no longer in table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try calculating the spatial neighbors again, but we'll make sure the new table is backed to the zarr store by using hp.tb.add_table_layer().\n",
    "from harpy.utils._keys import _REGION_KEY\n",
    "\n",
    "sq.gr.spatial_neighbors(\n",
    "    adata=sdata[\"table_transcriptomics_score_genes\"], \n",
    "    coord_type=\"generic\", # Set to 'generic' for targeted spatial transcriptomics\n",
    "    n_neighs=6, # Only used when delaunay = False\n",
    "    radius=None, # To compute the neighbors based on the radius\n",
    "    delaunay=False, # Whether to compute the graph from Delaunay triangulation\n",
    ")\n",
    "\n",
    "region = sdata[\"table_transcriptomics_score_genes\"].obs[_REGION_KEY].cat.categories.to_list()\n",
    "\n",
    "sdata = hp.tb.add_table_layer(\n",
    "    sdata,\n",
    "    adata=sdata.tables[\"table_transcriptomics_score_genes\"],\n",
    "    output_layer=\"table_transcriptomics_squidpy\",\n",
    "    region=region, # A list of regions to associate with the table data. Typically this is all unique elements in adata.obs[_REGION_KEY].\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect spatial connectivities of first 10 rows and colomns\n",
    "sdata.tables['table_transcriptomics_squidpy'].obsp['spatial_connectivities'].toarray()[0:10,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect number of neighbors (for first 10 cells)\n",
    "sdata.tables['table_transcriptomics_squidpy'].obsp['spatial_connectivities'].toarray().sum(axis=1)[0:10]\n",
    "\n",
    "# NOTE: Every cell has exactly 6 neighbors when using n_neigh=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect for every cell how many cells have it as a neighbor (for first 10 cells)\n",
    "sdata.tables['table_transcriptomics_squidpy'].obsp['spatial_connectivities'].toarray().sum(axis=0)[0:10]\n",
    "\n",
    "# NOTE: Not every cell is a neighbor of exactly 6 cells when using n_neigh=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Access the spatial connectivities matrix\n",
    "matrix = sdata.tables['table_transcriptomics_squidpy'].obsp['spatial_connectivities']\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 10), dpi=300)\n",
    "plt.imshow(matrix.toarray(), cmap='gray_r')\n",
    "plt.colorbar()  \n",
    "plt.title(\"Spatial Connectivities\", fontsize=18)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect spatial distances\n",
    "sdata.tables['table_transcriptomics_squidpy'].obsp['spatial_distances'].toarray()[0:4,0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Build a graph of spatial neighbors using a radius of 100 pixels. Inspect the neighbor relationships in both directions. How does this compare to the results for 6-nearest neighbors spatial graph? Try the same for Delaunay triangulation.\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "# radius-based spatial graphs\n",
    "from harpy.utils._keys import _REGION_KEY\n",
    "\n",
    "sq.gr.spatial_neighbors(\n",
    "    adata=sdata[\"table_transcriptomics_score_genes\"], \n",
    "    coord_type=\"generic\",\n",
    "    radius=100,\n",
    "    delaunay=False,\n",
    ")\n",
    "\n",
    "region = sdata[\"table_transcriptomics_score_genes\"].obs[_REGION_KEY].cat.categories.to_list()\n",
    "\n",
    "sdata = hp.tb.add_table_layer(\n",
    "    sdata,\n",
    "    adata=sdata.tables[\"table_transcriptomics_score_genes\"],\n",
    "    output_layer=\"table_transcriptomics_squidpy\",\n",
    "    region=region,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "print('Inspect spatial connectivities of first 10 rows and colomns:')\n",
    "display(sdata.tables['table_transcriptomics_squidpy'].obsp['spatial_connectivities'].toarray()[0:10,0:10])\n",
    "\n",
    "print('Inspect number of neighbors (for first 10 cells):')\n",
    "display(sdata.tables['table_transcriptomics_squidpy'].obsp['spatial_connectivities'].toarray().sum(axis=1)[0:10])\n",
    "\n",
    "print('Inspect for every cell how many cells have it as a neighbor (for first 10 cells):')\n",
    "display(sdata.tables['table_transcriptomics_squidpy'].obsp['spatial_connectivities'].toarray().sum(axis=0)[0:10])\n",
    "\n",
    "print('Plot spatial connectivities:')\n",
    "import matplotlib.pyplot as plt\n",
    "matrix = sdata.tables['table_transcriptomics_squidpy'].obsp['spatial_connectivities']\n",
    "\n",
    "plt.figure(figsize=(12, 10), dpi=300)\n",
    "plt.imshow(matrix.toarray(), cmap='gray_r')\n",
    "plt.colorbar()  \n",
    "plt.title(\"Spatial Connectivities\", fontsize=18)  \n",
    "plt.show()\n",
    "\n",
    "# Delaunay triangulation\n",
    "from harpy.utils._keys import _REGION_KEY\n",
    "\n",
    "sq.gr.spatial_neighbors(\n",
    "    adata=sdata[\"table_transcriptomics_score_genes\"], \n",
    "    coord_type=\"generic\",\n",
    "    delaunay=True,\n",
    ")\n",
    "\n",
    "region = sdata[\"table_transcriptomics_score_genes\"].obs[_REGION_KEY].cat.categories.to_list()\n",
    "\n",
    "sdata = hp.tb.add_table_layer(\n",
    "    sdata,\n",
    "    adata=sdata.tables[\"table_transcriptomics_score_genes\"],\n",
    "    output_layer=\"table_transcriptomics_squidpy\",\n",
    "    region=region,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "print('Inspect spatial connectivities of first 10 rows and colomns:')\n",
    "display(sdata.tables['table_transcriptomics_squidpy'].obsp['spatial_connectivities'].toarray()[0:10,0:10])\n",
    "\n",
    "print('Inspect number of neighbors (for first 10 cells):')\n",
    "display(sdata.tables['table_transcriptomics_squidpy'].obsp['spatial_connectivities'].toarray().sum(axis=1)[0:10])\n",
    "\n",
    "print('Inspect for every cell how many cells have it as a neighbor (for first 10 cells):')\n",
    "display(sdata.tables['table_transcriptomics_squidpy'].obsp['spatial_connectivities'].toarray().sum(axis=0)[0:10])\n",
    "\n",
    "print('Plot spatial connectivities:')\n",
    "import matplotlib.pyplot as plt\n",
    "matrix = sdata.tables['table_transcriptomics_squidpy'].obsp['spatial_connectivities']\n",
    "\n",
    "plt.figure(figsize=(12, 10), dpi=300)\n",
    "plt.imshow(matrix.toarray(), cmap='gray_r')\n",
    "plt.colorbar()  \n",
    "plt.title(\"Spatial Connectivities\", fontsize=18)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate neighborhood enrichment\n",
    "sdata = hp.tb.nhood_enrichment(\n",
    "    sdata, \n",
    "    labels_layer=\"segmentation_mask\", \n",
    "    table_layer=\"table_transcriptomics_squidpy\", \n",
    "    output_layer=\"table_transcriptomics_squidpy\", \n",
    "    celltype_column = \"annotation\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# Plot neighborhood enrichment\n",
    "hp.pl.nhood_enrichment(\n",
    "    sdata, \n",
    "    table_layer=\"table_transcriptomics_squidpy\",\n",
    ")\n",
    "\n",
    "# Add table layer to back to zarr\n",
    "sdata = hp.tb.add_table_layer(\n",
    "    sdata,\n",
    "    adata=sdata.tables[\"table_transcriptomics_squidpy\"],\n",
    "    output_layer=\"table_transcriptomics_squidpy\",\n",
    "    region=region,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Moran’s I global spatial auto-correlation statistics\n",
    "sq.gr.spatial_autocorr(\n",
    "    adata=sdata.tables[\"table_transcriptomics_squidpy\"],\n",
    "    mode=\"moran\",\n",
    "    n_perms=100,\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "# Add table layer to back to zarr\n",
    "sdata = hp.tb.add_table_layer(\n",
    "    sdata,\n",
    "    adata=sdata.tables[\"table_transcriptomics_squidpy\"],\n",
    "    output_layer=\"table_transcriptomics_squidpy\",\n",
    "    region=region,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect highest Moran's I scores\n",
    "sdata.tables[\"table_transcriptomics_squidpy\"].uns[\"moranI\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect lowest Moran's I scores\n",
    "sdata.tables[\"table_transcriptomics_squidpy\"].uns[\"moranI\"].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interactive(sdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Region annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region annotation in Napari\n",
    "\n",
    "# from napari_spatialdata import Interactive\n",
    "# Interactive(sdata)\n",
    "\n",
    "# NOTE: - In napari, create a new shapes layer, annotate a region of interest, save to sdata using Shift + E and close Napari.\n",
    "#       - For more info, see: https://spatialdata.scverse.org/en/latest/tutorials/notebooks/notebooks/examples/napari_rois.html \n",
    "#       - Currently, there is only support for saving rectangles, polygons and points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the sdata object to see whether the layer was correctly added\n",
    "sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.pl.plot_shapes( sdata, img_layer = \"clahe\", shapes_layer=\"segmentation_mask_boundaries\", crd = [ 2000, 4000, 2000, 4000 ], figsize=(5,5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell only for unit tests to pass\n",
    "from spatialdata.models import ShapesModel\n",
    "\n",
    "if unit_testing:\n",
    "    import geopandas as gpd\n",
    "    from shapely.geometry import box\n",
    "\n",
    "    # Define the rectangle boundaries\n",
    "    x_min, y_min, x_max, y_max = 2250, 2250, 3000, 3000\n",
    "\n",
    "    # Create a Shapely box (rectangle)\n",
    "    rectangle = box(x_min, y_min, x_max, y_max)\n",
    "\n",
    "    # Create a GeoDataFrame\n",
    "    polygons= gpd.GeoDataFrame({'geometry': [rectangle]})\n",
    "    polygons=ShapesModel.parse( polygons )\n",
    "    sdata.shapes[ \"region_annotation\" ] = polygons\n",
    "    sdata.write_element( element_name=\"region_annotation\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not unit_testing:\n",
    "    # We need to make sure the shapes layer is backed to zarr\n",
    "    sdata.write_element(element_name='region_annotation')\n",
    "    sdata = read_zarr(sdata.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we can also import a GeoJSON from another source (e.g. QuPath)\n",
    "\n",
    "# import geopandas as gpd\n",
    "# gdf_regions = gpd.read_file(path_to_GeoJSON)\n",
    "# sdata = hp.sh.add_shapes_layer(sdata, input=gdf_regions, output_layer='region_annotation', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "# Get spatial coordinates\n",
    "spatial_coords = sdata.tables['table_transcriptomics_squidpy'].obsm[\"spatial\"]\n",
    "spatial_coords_df = pd.DataFrame(spatial_coords, columns=[\"x\", \"y\"], index=sdata.tables['table_transcriptomics_squidpy'].obs.index)\n",
    "\n",
    "# Define function to assign region annotations to cells\n",
    "def assign_region(centroid, gdf):\n",
    "    for index, row in gdf.iterrows():\n",
    "        if Point(centroid).within(row[\"geometry\"]):\n",
    "            return \"Yes\"\n",
    "    return \"No\"  \n",
    "\n",
    "# Create new column in obs to check if cells are in region\n",
    "sdata.tables['table_transcriptomics_squidpy'].obs[\"in_region\"] = spatial_coords_df.apply(lambda row: assign_region((row[\"x\"], row[\"y\"]), sdata.shapes[\"region_annotation\"]), axis=1)\n",
    "\n",
    "# Add table layer to back to zarr\n",
    "sdata = hp.tb.add_table_layer(\n",
    "    sdata,\n",
    "    adata=sdata.tables[\"table_transcriptomics_squidpy\"],\n",
    "    output_layer=\"table_transcriptomics_squidpy\",\n",
    "    region=region,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check obs\n",
    "sdata.tables['table_transcriptomics_squidpy'].obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot region annotation shapes layer\n",
    "hp.pl.plot_shapes(\n",
    "    sdata, \n",
    "    img_layer='clahe', \n",
    "    shapes_layer='region_annotation',\n",
    "    alpha=0.5,\n",
    "    crd=[2000, 4000, 2000, 4000]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cells colored according to in_region column\n",
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    column=\"in_region\",\n",
    "    img_layer=\"clahe\",\n",
    "    table_layer=\"table_transcriptomics_squidpy\",\n",
    "    shapes_layer=\"segmentation_mask_boundaries\",\n",
    "    linewidth=0,\n",
    "    alpha=0.7,\n",
    "    cmap=\"rainbow\",\n",
    "    crd=[2000, 4000, 2000, 4000]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 TissUUmaps\n",
    "\n",
    "TissUUmaps is a handy visualization software that allows easy interactive exploration of your spatial data. It can be used to visualize data from an AnnData .h5ad file or from a csv-file. You can also simultaneously visualize images (multiple file types, including tiff) and regions (GeoJSON). \n",
    "\n",
    "It can be installed using this link: https://tissuumaps.github.io/installation/ \\\n",
    "Documentation can be found here: https://tissuumaps.github.io/TissUUmaps-docs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export image as tiff\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "\n",
    "if not unit_testing:\n",
    "\n",
    "    # Save AnnData as h5ad\n",
    "    sdata.tables[\"table_transcriptomics_squidpy\"].write(os.path.join(OUTPUT_DIR, 'adata.h5ad'))\n",
    "\n",
    "    # Export shapes layer as GeoJSON\n",
    "    sdata.shapes['region_annotation'].to_file(os.path.join(OUTPUT_DIR, \"region_annotation.geojson\"), driver=\"GeoJSON\")\n",
    "\n",
    "\n",
    "    img = sdata.images['clahe'].data.compute()\n",
    "    imsave(os.path.join(OUTPUT_DIR, \"clahe.tiff\"), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training_env_11_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
