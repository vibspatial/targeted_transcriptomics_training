{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import harpy as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/arnedf/Downloads/xenium/\"\n",
    "#path = \"/hive/hubmap/data/public/spatial-data-workshop/TMA2/xenium\"\n",
    "\n",
    "input_path = [\n",
    "    os.path.join( path, \"output-XETG00247__0021229__Region_1__20240319__210701\"),\n",
    "    os.path.join( path, \"output-XETG00247__0021229__Region_3__20240319__210702\"),\n",
    "    os.path.join( path, \"output-XETG00247__0021229__Region_4__20240319__210702\"),\n",
    "    #os.path.join( path, \"output-XETG00247__0021229__Region_6__20240319__210702\"),\n",
    "    #os.path.join( path, \"output-XETG00247__0021229__Region_7__20240319__210702\"),\n",
    "    #os.path.join( path, \"output-XETG00247__0021229__Region_10__20240319__210702\"),\n",
    "    #os.path.join( path, \"output-XETG00247__0021229__Region_11__20240319__210702\"),\n",
    "]\n",
    "\n",
    "#regions = [ \"region1\", \"region3\", \"region4\", \"region6\", \"region7\", \"region10\", \"region11\" ]\n",
    "regions = [ \"region1\", \"region3\", \"region4\", ]\n",
    "\n",
    "OUTPUT_DIR = \"/Users/arnedf/VIB/DATA/test_data/hubmap_training\"\n",
    "# OUTPUT_DIR = \"/hive/user-workspaces/adefauw/1538/xenium_data\"\n",
    "\n",
    "crop=True\n",
    "\n",
    "sdata = hp.io.xenium(\n",
    "    input_path,\n",
    "    to_coordinate_system=regions,\n",
    "    aligned_images=True,\n",
    "    cells_table=True,\n",
    "    nucleus_labels=True,\n",
    "    cells_labels=True,\n",
    "    filter_gene_names=['Unassigned','NegControl','Deprecated'],\n",
    "    output= os.path.join( OUTPUT_DIR, \"sdata_xenium.zarr\" ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napari_spatialdata import Interactive\n",
    "\n",
    "Interactive(sdata )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise:\n",
    "\n",
    "Preprocess the data. Use the `harpy` functions `hp.im.min_max_filtering` and `hp.im.enhance_contrast`.\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "from spatialdata.transformations import get_transformation\n",
    "\n",
    "if crop is True:\n",
    "  crd_region1 = [ 4000, 10000, 4000, 10000 ]\n",
    "  crd_region3 = [ 5000, 12000, 0, 6000 ]\n",
    "  crd_region4 = [ 400, 6400 , 0, 6000 ]\n",
    "  crd_region6 = [ 600, 6600, 4000, 10000 ]\n",
    "  crd_region7 = [ 2000, 8000, 9000, 15000 ]\n",
    "  crd_region10 = [ 4000, 10000, 2600, 8600 ]\n",
    "  crd_region11 = [ 2500, 8500, 3000, 9000 ]\n",
    "  crd = [ crd_region1, crd_region3, crd_region4, crd_region6, crd_region7, crd_region10, crd_region11 ]\n",
    "else:\n",
    "    crd=None\n",
    "\n",
    "for _crd,_region in zip(crd, regions, strict=False):\n",
    "\n",
    "  sdata = hp.im.min_max_filtering(\n",
    "      sdata,\n",
    "      img_layer=f\"morphology_focus_{_region}\",\n",
    "      output_layer=f\"preprocessed_{_region}\",\n",
    "      size_min_max_filter=51,   # specify a single value to be used for all channels, or specify a list with a value for each channel\n",
    "      crd = _crd,\n",
    "      to_coordinate_system=_region,\n",
    "      overwrite=True,\n",
    "        )\n",
    "  \n",
    "  sdata = hp.im.enhance_contrast(\n",
    "      sdata,\n",
    "      img_layer=f\"preprocessed_{_region}\",\n",
    "      output_layer=f\"preprocessed_{_region}\",\n",
    "      contrast_clip=3.5,        # specify a single value to be used for all channels, or specify a list with a value for each channel\n",
    "      chunks=None,\n",
    "      overwrite=True,\n",
    "        )\n",
    "  \n",
    "  # rechunk on disk, in this way we have 'optimal' chunk size for segmentation\n",
    "  sdata=hp.im.add_image_layer(\n",
    "      sdata,\n",
    "      arr=sdata[ f\"preprocessed_{_region}\" ].data.rechunk( 2048 ),\n",
    "      transformations=get_transformation( sdata[ f\"preprocessed_{_region}\" ], get_all=True ),\n",
    "      output_layer = f\"preprocessed_{_region}\",\n",
    "      overwrite=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatialdata.transformations import get_transformation\n",
    "\n",
    "if crop is True:\n",
    "  crd_region1 = [ 4000, 10000, 4000, 10000 ]\n",
    "  crd_region3 = [ 5000, 12000, 0, 6000 ]\n",
    "  crd_region4 = [ 400, 6400 , 0, 6000 ]\n",
    "  crd_region6 = [ 600, 6600, 4000, 10000 ]\n",
    "  crd_region7 = [ 2000, 8000, 9000, 15000 ]\n",
    "  crd_region10 = [ 4000, 10000, 2600, 8600 ]\n",
    "  crd_region11 = [ 2500, 8500, 3000, 9000 ]\n",
    "  crd = [ crd_region1, crd_region3, crd_region4, crd_region6, crd_region7, crd_region10, crd_region11 ]\n",
    "else:\n",
    "    crd=None\n",
    "\n",
    "for _crd,_region in zip(crd, regions, strict=False):\n",
    "\n",
    "  sdata = hp.im.min_max_filtering(\n",
    "      sdata,\n",
    "      img_layer=f\"morphology_focus_{_region}\",\n",
    "      output_layer=f\"preprocessed_{_region}\",\n",
    "      size_min_max_filter=51,   # specify a single value to be used for all channels, or specify a list with a value for each channel\n",
    "      crd = _crd,\n",
    "      to_coordinate_system=_region,\n",
    "      overwrite=True,\n",
    "        )\n",
    "  \n",
    "  sdata = hp.im.enhance_contrast(\n",
    "      sdata,\n",
    "      img_layer=f\"preprocessed_{_region}\",\n",
    "      output_layer=f\"preprocessed_{_region}\",\n",
    "      contrast_clip=3.5,        # specify a single value to be used for all channels, or specify a list with a value for each channel\n",
    "      chunks=None,\n",
    "      overwrite=True,\n",
    "        )\n",
    "  \n",
    "  # rechunk on disk, in this way we have 'optimal' chunk size for segmentation\n",
    "  sdata=hp.im.add_image_layer(\n",
    "      sdata,\n",
    "      arr=sdata[ f\"preprocessed_{_region}\" ].data.rechunk( 2048 ),\n",
    "      transformations=get_transformation( sdata[ f\"preprocessed_{_region}\" ], get_all=True ),\n",
    "      output_layer = f\"preprocessed_{_region}\",\n",
    "      overwrite=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise:\n",
    "\n",
    "Visualize the data. Show both original and preprocessed images using the `harpy` function `hp.pl.plot_image`.\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "hp.pl.plot_image(\n",
    "    sdata,\n",
    "    img_layer=[ \"morphology_focus_region1\", \"preprocessed_region1\", ],\n",
    "    crd = crd_region1,\n",
    "    to_coordinate_system=\"region1\",\n",
    "    figsize=(10,10),\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segment using Cellpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "# # Create a local Dask cluster\n",
    "cluster = LocalCluster(\n",
    "     n_workers=8,              # Number of worker processes\n",
    "     threads_per_worker=1,    # Number of threads per worker\n",
    "     memory_limit=\"32GB\",      # Memory limit per worker\n",
    " )\n",
    "\n",
    "# # Connect a Client to the cluster\n",
    "client = Client(cluster)\n",
    "\n",
    "# # Print the Dask dashboard link\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from harpy.image import cellpose_callable\n",
    "\n",
    "device = \"cpu\"  # mps broken in cellpose (macOS), see https://github.com/MouseLand/cellpose/issues/1063\n",
    "\n",
    "# find good crop for each region\n",
    "\n",
    "for _region in regions:\n",
    "\n",
    "    sdata = hp.im.segment(\n",
    "        sdata,\n",
    "        img_layer=f\"preprocessed_{_region}\",  # or \"morphology_focus_global\"\n",
    "        depth=200,\n",
    "        model=cellpose_callable,\n",
    "        # parameters that will be passed to the callable _cellpose\n",
    "        pretrained_model = \"nuclei\",\n",
    "        device = device,\n",
    "        diameter=30,\n",
    "        flow_threshold=0.9,\n",
    "        cellprob_threshold=-4,\n",
    "        channels=[1,0],\n",
    "        output_labels_layer=f\"segmentation_mask_{_region}\",\n",
    "        output_shapes_layer=f\"segmentation_boundaries_{_region}\",\n",
    "        to_coordinate_system=_region,\n",
    "        overwrite=True,\n",
    "    )\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise:\n",
    "\n",
    "Convert the labels layers `cell_labels_region1` and `nucleus_labels_region1` to a shapes layer using the `harpy` function `harpy.sh.vectorize`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "import dask\n",
    "with dask.config.set(scheduler='processes'):\n",
    "    sdata=hp.sh.vectorize( sdata, labels_layer=\"cell_labels_region1\", output_layer=\"cell_shapes_region1\", overwrite=True )\n",
    "    sdata=hp.sh.vectorize( sdata, labels_layer=\"nucleus_labels_region1\", output_layer=\"nucleus_shapes_region1\", overwrite=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer=\"preprocessed_region1\",\n",
    "    shapes_layer=[\"segmentation_boundaries_region1\", \"cell_shapes_region1\"],\n",
    "    crd = [4500, 5500, 4500, 5500],\n",
    "    to_coordinate_system=\"region1\",\n",
    "    figsize=(8,8),\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer=\"preprocessed_region1\",\n",
    "    shapes_layer=[\"segmentation_boundaries_region1\", \"cell_shapes_region1\"],\n",
    "    crd = [8500, 10000, 8500, 10000],\n",
    "    to_coordinate_system=\"region1\",\n",
    "    figsize=(8,8),\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create one AnnData object, with data from all regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _region in regions:\n",
    "\n",
    "    sdata=hp.tb.allocate( \n",
    "        sdata,\n",
    "        labels_layer=f\"segmentation_mask_{_region}\",\n",
    "        points_layer=f\"transcripts_{_region}\",\n",
    "        output_layer=\"table_harpy\",\n",
    "        to_coordinate_system=_region,\n",
    "        chunks=None,\n",
    "        append=True,\n",
    "        overwrite=True,\n",
    "        update_shapes_layers=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[ \"table_harpy\" ].obs[ \"fov_labels\" ].cat.categories.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[ \"table_harpy\" ].obs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = hp.tb.preprocess_transcriptomics(\n",
    "    sdata,\n",
    "    labels_layer=sdata[ \"table_harpy\" ].obs[ \"fov_labels\" ].cat.categories,\n",
    "    table_layer=\"table_harpy\",\n",
    "    output_layer=\"table_harpy\",  # write results to a new slot, we could also write to the same slot (when passing overwrite==True).\n",
    "    min_counts=10,\n",
    "    min_cells=5,\n",
    "    size_norm=True,\n",
    "    n_comps=50,\n",
    "    overwrite=True,\n",
    "    update_shapes_layers=False,\n",
    ")\n",
    "\n",
    "sdata = hp.tb.filter_on_size(\n",
    "    sdata,\n",
    "    labels_layer=sdata[ \"table_harpy\" ].obs[ \"fov_labels\" ].cat.categories,\n",
    "    table_layer=\"table_harpy\",\n",
    "    output_layer=\"table_harpy\",\n",
    "    min_size=500,\n",
    "    max_size=100000,\n",
    "    update_shapes_layers=False,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leiden clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "sdata = hp.tb.leiden(\n",
    "    sdata,\n",
    "    labels_layer=sdata[ \"table_harpy\" ].obs[ \"fov_labels\" ].cat.categories,\n",
    "    table_layer=\"table_harpy\",\n",
    "    output_layer=\"table_harpy\",\n",
    "    calculate_umap=True,\n",
    "    calculate_neighbors=True,\n",
    "    n_pcs=17,\n",
    "    n_neighbors=35,\n",
    "    resolution=0.8,\n",
    "    rank_genes=True,\n",
    "    key_added=\"leiden\",\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "sc.pl.umap(\n",
    "    sdata.tables[\"table_harpy\"],\n",
    "    color=[\"leiden\"],\n",
    "    show=True,\n",
    "    )\n",
    "\n",
    "sc.pl.rank_genes_groups(\n",
    "    sdata.tables[\"table_harpy\"],\n",
    "    n_genes=8,\n",
    "    sharey=False,\n",
    "    show=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    sdata.tables[\"table_harpy\"],\n",
    "    color=[\"fov_labels\"],\n",
    "    show=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise:\n",
    "\n",
    "Plot the leiden clusters, either using `harpy.pl.plot_shapes` or `spatialdata-plot`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer=\"preprocessed_region1\",\n",
    "    shapes_layer=\"segmentation_boundaries_region1\",\n",
    "    region = \"segmentation_mask_region1\",\n",
    "    to_coordinate_system=\"region1\",\n",
    "    table_layer=\"table_harpy\",\n",
    "    column=\"leiden\",\n",
    "    alpha=1,\n",
    "    linewidth=0,\n",
    "    channel=\"DAPI\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "column = \"leiden\"\n",
    "\n",
    "adata = sdata.tables[ \"table_harpy\" ]\n",
    "\n",
    "sdata_small = sdata.query.bounding_box(\n",
    "    min_coordinate=[4000, 4000], max_coordinate=[10000, 10000], axes=(\"x\", \"y\"), target_coordinate_system=\"region1\"\n",
    ")\n",
    "\n",
    "sdata_small.pl.render_labels(\"segmentation_mask_region1\", color=column, cmap=None, method=\"datashader\", fill_alpha=1, table_name= \"table_harpy\").pl.show(\n",
    "    coordinate_systems=\"region1\", ax=ax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napari_spatialdata import Interactive\n",
    "\n",
    "# del sdata[ \"table_harpy\"].uns[ \"leiden_colors\" ]\n",
    "\n",
    "Interactive( sdata )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training_env_14_4_25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
