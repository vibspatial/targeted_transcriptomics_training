{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import harpy as hp\n",
    "\n",
    "data_path = \"/Users/arnedf/VIB/DATA/hubmap\"\n",
    "# data_path = \"/hive/hubmap/data/public/spatial-data-workshop/TMA2/phenocycler\"\n",
    "\n",
    "output_path = \"/Users/arnedf/VIB/DATA/hubmap\"\n",
    "# output_path = \"/hive/user-workspaces/adefauw/1538/phenocycler_data\"\n",
    "\n",
    "file = \"Segmented_Bronchi_TMA_Scan1.er.qptiff\"\n",
    "\n",
    "input_path = os.path.join( data_path, file )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from typing import Generator\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "import dask.array as da\n",
    "import ome_types\n",
    "from ome_types.model import UnitsLength\n",
    "import tifffile\n",
    "\n",
    "# Class for basic Tiff and QPTiff file reading.\n",
    "\n",
    "class Tiff:\n",
    "    \"\"\" Class for reading TIFF and QPTIFF files. \"\"\"\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.tif = None\n",
    "        self.pages = []\n",
    "        self.channel_names = []\n",
    "        self.pixel_size_um = None\n",
    "\n",
    "    def open(self):\n",
    "        \"\"\" Open the file for reading \"\"\"\n",
    "        self.tif = tifffile.TiffFile(self.filepath)\n",
    "        self.pages = self.tif.series[0].pages\n",
    "        self.channel_names = self._get_channel_names()\n",
    "        self.pixel_size_um = self._get_pixel_size_um()\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\" Close the file \"\"\"\n",
    "        if self.tif:\n",
    "            self.tif.close()\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.open()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, exc_tb):\n",
    "        self.close()\n",
    "\n",
    "    def read_channel(self, name):\n",
    "        \"\"\" Read the channel with the given name from the tiff/qptiff file and\n",
    "            return the pixel data as a numpy array. \"\"\"\n",
    "        idx = self.channel_names.index(name)\n",
    "        return self.pages[idx].asarray()\n",
    "    \n",
    "    @contextmanager\n",
    "    def dask_array(self) -> Generator[da.Array, None, None]:\n",
    "        \"\"\" Read the full tiff/qptiff file into a dask array of dimensions (c, y, x). \"\"\"\n",
    "\n",
    "        # Represent each channel of the TIFF file as a zarr store (a tifffile.ZarrTiffStore).\n",
    "        # No temporary zarr files on disk are created. Instead, when the zarr store is accessed,\n",
    "        # the tifffile library will read the pixel data from the underlying existing tiff file.\n",
    "        # Dask arrays are then created from these zarr stores.\n",
    "        # This proces is lazy and almost instantaneous.\n",
    "        zarr_stores = []\n",
    "        dask_arrays = []\n",
    "        for channel in range(len(self.channel_names)):\n",
    "            zarr_store = tifffile.imread(self.filepath, key=channel, aszarr=True)\n",
    "            zarr_stores.append(zarr_store)\n",
    "            dask_array = da.from_zarr(zarr_store)\n",
    "            dask_arrays.append(dask_array)\n",
    "\n",
    "        # Combine dask arrays for each channel into a single dask array.\n",
    "        full_dask_image = da.stack(dask_arrays)\n",
    "        yield full_dask_image\n",
    "\n",
    "        # Close all ZarrTiffStore's\n",
    "        for zarr_store in zarr_stores:\n",
    "            zarr_store.close()\n",
    "\n",
    "    def _get_channel_names(self):\n",
    "        if self.pages.kind.lower() == 'qpi':\n",
    "            # It's a PerkinElmer qptiff, for example from a VectraPolaris scanner.\n",
    "            # These apparently do not have OME metadata, but store metadata in a \n",
    "            # description tag per channel image. \n",
    "            # The name of fluorophore is stored in the \"Name\" tag. More recent versions\n",
    "            # of the file format have an additional \"Biomarker\" tag that stores the\n",
    "            # detected molecule (e.g. Ki67, Podoplanin, ...). If present we will use the biomarker\n",
    "            # as channel name, otherwise the fluorophore name.\n",
    "            # See also the bioformats VectroPolaris qptiff reader:\n",
    "            # https://github.com/ome/bioformats/blob/develop/components/formats-gpl/src/loci/formats/in/VectraReader.java\n",
    "            # and the Akoya PhenoChart user guide (appendix B): https://www.akoyabio.com/wp-content/uploads/PhenochartUserManual_2_2_0_rev0.pdf\n",
    "            channel_names = []\n",
    "            for page in self.pages:\n",
    "                description = ElementTree.fromstring(page.description)\n",
    "                \n",
    "                image_type = description.find('ImageType').text\n",
    "                assert image_type == \"FullResolution\"\n",
    "\n",
    "                biomarker_tag = description.find('Biomarker')\n",
    "                if biomarker_tag is not None:\n",
    "                    channel_name = biomarker_tag.text\n",
    "                else:\n",
    "                    name_tag = description.find('Name')\n",
    "                    if name_tag is not None:\n",
    "                        channel_name = name_tag.text\n",
    "                    else:\n",
    "                        channel_name = None\n",
    "                channel_names.append(channel_name)\n",
    "            return channel_names\n",
    "        elif self.pages.kind.lower() == 'ome':\n",
    "            # If the qptiff has OME metadata (like Lunaphore COMET)\n",
    "            # read it from the OME XML tag.\n",
    "            xml = tifffile.tiffcomment(self.filepath)\n",
    "            assert xml\n",
    "            ome = ome_types.from_xml(xml)\n",
    "            assert len(ome.images) == 1\n",
    "            channel_names = [channel.name for channel in ome.images[0].pixels.channels]\n",
    "            return channel_names\n",
    "        elif self.pages.kind.lower() == 'imagej':\n",
    "            # ImageJ compatible TIFFs have yet another way to store metadata.\n",
    "            # The channel names are stored under the \"Labels\" key in this dict.\n",
    "            return self.tif.imagej_metadata['Labels']\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    # def _get_pixel_size_um(self):\n",
    "    #     page = self.pages[0]  # pick the first channel, the resolution of all channels is assumed to be identical\n",
    "    #     scale = 1000000 if page.tags['ResolutionUnit'].value == tifffile.RESUNIT.NONE else None  # ImageJ compatible TIFFs (sometimes?) don't specify the ResolutionUnit tag, but assume micrometers\n",
    "    #     resolution = page.get_resolution(tifffile.RESUNIT.MICROMETER, scale=scale)\n",
    "    #     assert resolution[0] == resolution[1], \"(qp)tiff x and y resolution are not the same\"\n",
    "    #     pixelsize = 1 / resolution[0]\n",
    "    #     return pixelsize\n",
    "    \n",
    "    def _get_pixel_size_um(self) -> float | None:\n",
    "        # If the TIFF file is an OME TIFF, and the OME XML tag specifies a physical size, then return this value\n",
    "        if self.tif.is_ome:\n",
    "            pixelsize = self._ome_get_physical_size_x_um()\n",
    "            if pixelsize is not None:\n",
    "                return pixelsize\n",
    "            \n",
    "        # If the file is not OME, or the OME XML file did not specify a pixelsize,\n",
    "        # then attempt to get it from the regular TIFF metadata tags.\n",
    "        page = self.pages[0]  # pick the first channel, the resolution of all channels is assumed to be identical\n",
    "        unit = page.tags['ResolutionUnit'].value\n",
    "        if unit == tifffile.RESUNIT.NONE:\n",
    "            return None  # if it's an ImageJ TIFF file, we could check TiffTag 270 ImageDescription, which may contain a units specification, but for now we simply don't support this case. Neither does QuPath, it seems.\n",
    "        resolution = page.get_resolution(tifffile.RESUNIT.MICROMETER)\n",
    "        assert resolution[0] == resolution[1], \"(qp)tiff x and y resolution are not the same\"\n",
    "        pixelsize = 1 / resolution[0]\n",
    "        return pixelsize\n",
    "        \n",
    "        \n",
    "    def _ome_get_physical_size_x_um(self) -> float | None:\n",
    "        assert self.tif.is_ome\n",
    "        ome_xml = self.tif.ome_metadata\n",
    "        ome = ome_types.from_xml(ome_xml, validate=False)\n",
    "        pixels = ome.images[0].pixels\n",
    "        size = pixels.physical_size_x\n",
    "        if size is None:\n",
    "            return None\n",
    "        match pixels.physical_size_x_unit:\n",
    "            case UnitsLength.NANOMETER:\n",
    "                return size / 1000.0\n",
    "            case UnitsLength.MICROMETER:\n",
    "                return size\n",
    "            case UnitsLength.MILLIMETER:\n",
    "                return size * 1000.0\n",
    "            case UnitsLength.CENTIMETER:\n",
    "                return size * 10000.0\n",
    "            case _:\n",
    "                assert False, f\"OME unit {pixels.physical_size_x_unit} is not supported\"\n",
    "\n",
    "    # Note about tiff/qptiff pages:\n",
    "    # - TiffFile.pages[] has *all* the images in the qptiff file,\n",
    "    #   including the different lower-resolution levels in the image pyramid,\n",
    "    #   the overview and thumbnail images etc.\n",
    "    # - TiffFile.series[0].pages[] on the other hand only stores the full resolution\n",
    "    #   images with the actual image data, which is exactly what we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create spatialdata object with multiscale image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes about 8 min on mac OS M2\n",
    "\n",
    "zarr_path = os.path.join( output_path, \"sdata_phenocycler.zarr\" )\n",
    "\n",
    "with Tiff(input_path) as tif:\n",
    "    channel_names = tif.channel_names\n",
    "    pixel_size_um = tif.pixel_size_um\n",
    "\n",
    "with Tiff(input_path) as tif:\n",
    "           with tif.dask_array() as dask_img:\n",
    "               hp.io.create_sdata(\n",
    "                   dask_img,\n",
    "                   dims=['c', 'y', 'x'],\n",
    "                   output_path=zarr_path,\n",
    "                   img_layer=\"scan\",\n",
    "                   chunks=2048,\n",
    "                   scale_factors=[2, 2, 2, 2, 2],\n",
    "                   c_coords=tif.channel_names\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from spatialdata import read_zarr\n",
    "\n",
    "sdata=read_zarr( os.path.join( output_path, \"sdata_phenocycler.zarr\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise:\n",
    "\n",
    "crop out each region, and save each one separately in its own coordinate space:\n",
    "\n",
    "- read in the polygons that define each region (`geopandas.read_file(...)`).\n",
    "- add the polygons to the SpatialData object (`harpy.sh.add_shapes_layer(...)`).\n",
    "- rasterize the polygons (creation of the corresponding mask) ( `harpy.im.rasterize(...)`).\n",
    "- extract the region (`dask.where(...)`).\n",
    "- add the image to the SpatialData object (`harpy.im.add_image_layer(...)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from spatialdata.transformations import Translation\n",
    "from harpy.image._image import _get_spatial_element\n",
    "\n",
    "# takes 3 min on macOS M2\n",
    "\n",
    "tma_2_1_2 = \"D231-RLL-14C2-HM-TMA-2-1-2.geojson\" # region 1\n",
    "tma_2_2_2 = \"D239-RLL-19C2-HM-TMA-2-2-2.geojson\" \n",
    "tma_2_3_2 = \"D260-RLL-12C2-HM-TMA-2-3-2.geojson\" # region 3\n",
    "tma_2_4_2 = \"D264-LLL-11C1-HM-TMA-2-4-2.geojson\" # region 4\n",
    "tma_2_5_2 = \"D264-LLL-11C2-HM-TMA-2-5-2.geojson\"\n",
    "tma_2_6_2 = \"D265-RLL-10C2-HM-TMA-2-6-2.geojson\" # region 6\n",
    "tma_2_7_2 = \"D271-RLL-13D4-HM-TMA-2-7-2.geojson\" # region 7\n",
    "tma_2_8_2 = \"D292-RLL-14C3-HM-TMA-2-8-2.geojson\" \n",
    "tma_2_9_2 = \"D341-RLL-14C2-HM-TMA-2-9-2.geojson\"\n",
    "tma_2_10_2 = \"D346-RLL-17C3-HM-TMA-2-10-2.geojson\" # region 10\n",
    "\n",
    "tma_paths = [ tma_2_1_2, tma_2_2_2, tma_2_3_2, tma_2_4_2, tma_2_5_2, tma_2_6_2, tma_2_7_2, tma_2_8_2, tma_2_9_2, tma_2_10_2 ]\n",
    "tma_name =  [ \"region1\", \"region2\", \"region3\", \"region4\", \"region5\", \"region6\", \"region7\", \"region8\", \"region9\", \"region10\" ]\n",
    "\n",
    "se_image = _get_spatial_element( sdata, layer = \"scan\" )\n",
    "\n",
    "for _tma_path, _tma_name in zip(tma_paths, tma_name, strict=True):\n",
    "\n",
    "    # Read the GeoJSON file\n",
    "    gdf = gpd.read_file( os.path.join( data_path, _tma_path ) )\n",
    "    gdf.index = gdf.index +1\n",
    "    sdata = hp.sh.add_shapes_layer( sdata, input=gdf, output_layer=_tma_name, overwrite=True )\n",
    "\n",
    "    # rasterize the shapes layer\n",
    "    sdata = hp.im.rasterize(\n",
    "        sdata,\n",
    "        shapes_layer=_tma_name,\n",
    "        output_layer=f\"{_tma_name}_labels\",\n",
    "        out_shape= se_image.shape[ 1: ],\n",
    "        chunks = 2048,\n",
    "        overwrite=True,\n",
    "        scale_factors=[ 2,2,2,2,2 ],\n",
    "        )\n",
    "    \n",
    "    se_mask = _get_spatial_element(sdata, layer=f\"{_tma_name}_labels\" )\n",
    "\n",
    "    mask = se_mask.data\n",
    "    image = se_image.data\n",
    "\n",
    "    mask = mask[None, ...]\n",
    "\n",
    "    # create a mask\n",
    "    masked_image = da.where(mask == 1, image, 0)\n",
    "\n",
    "    x_min, y_min, x_max, y_max = sdata[ _tma_name ].geometry.total_bounds.astype( int )\n",
    "\n",
    "    translation = Translation( translation=[x_min, y_min], axes = (\"x\", \"y\") )\n",
    "\n",
    "    masked_image = masked_image[ :, y_min: y_max, x_min: x_max ]\n",
    "\n",
    "    sdata = hp.im.add_image_layer(\n",
    "        sdata,\n",
    "        arr = masked_image.rechunk( 2048 ),\n",
    "        output_layer=f\"scan_{_tma_name}\",\n",
    "        transformations={ _tma_name: translation },\n",
    "        c_coords=se_image.c.data,\n",
    "        overwrite=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spatialdata_plot\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "vmax = 500\n",
    "vmin = 100\n",
    "\n",
    "norm = Normalize(vmax=vmax, vmin=vmin, clip=True)\n",
    "\n",
    "sdata.pl.render_images(\n",
    "    element = \"scan\",\n",
    "    channel = \"DAPI\",\n",
    "    scale = \"scale3\",\n",
    "    cmap = \"gray\",\n",
    "    norm = norm,\n",
    "    ).pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise:\n",
    "\n",
    "Plot each region using either `harpy` or `spatialdata-plot`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "for _tma_name in tma_name:\n",
    "    print( _tma_name )\n",
    "    hp.pl.plot_image(\n",
    "        sdata,\n",
    "        img_layer=f\"scan_{_tma_name}\",\n",
    "        channel=\"DAPI\",\n",
    "        figsize=(5,5),\n",
    "        to_coordinate_system=_tma_name,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select 4 channels (DAPI, CD45, CD68, CD14), and segment using InstanSeg.\n",
    "\n",
    "For optimal segmentation results a more careful selection of channels is probably necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.pl.plot_image(\n",
    "    sdata,\n",
    "    img_layer= \"scan_region1\",\n",
    "    channel = \"CD45\",\n",
    "    to_coordinate_system = \"region1\",\n",
    "    vmin_img = 50,\n",
    "    vmax_img = 1000,\n",
    "    figsize = (8,8),\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.pl.plot_image(\n",
    "    sdata,\n",
    "    img_layer= \"scan_region1\",\n",
    "    channel = \"CD68\",\n",
    "    to_coordinate_system = \"region1\",\n",
    "    vmin_img = 50,\n",
    "    vmax_img = 1000,\n",
    "    figsize = (8,8),\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.pl.plot_image(\n",
    "    sdata,\n",
    "    img_layer = \"scan_region1\",\n",
    "    channel = \"CD14\",\n",
    "    to_coordinate_system = \"region1\",\n",
    "    vmin_img = 200,\n",
    "    vmax_img = 500,\n",
    "    figsize = (8,8),\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import tempfile\n",
    "\n",
    "OUTPUT_DIR =  tempfile.gettempdir()\n",
    "\n",
    "def download_and_unzip(url, extract_to):\n",
    "    try:\n",
    "        os.makedirs(extract_to, exist_ok=False)\n",
    "    except FileExistsError:\n",
    "        print(\"Model already downloaded.\")\n",
    "        return\n",
    "    local_zip_path = os.path.join(extract_to, 'downloaded.zip')\n",
    "    print(\"Downloading...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    with open(local_zip_path, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "\n",
    "    print(\"Unzipping...\")\n",
    "    with zipfile.ZipFile(local_zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    os.remove(local_zip_path)\n",
    "    print(f\"Done! Files extracted to: {extract_to}\")\n",
    "\n",
    "url = \"https://github.com/instanseg/instanseg/releases/download/instanseg_models_v0.1.0/fluorescence_nuclei_and_cells.zip\"\n",
    "target_path = os.path.join(OUTPUT_DIR, \"fluorescence_nuclei_and_cells\" )\n",
    "download_and_unzip(url, target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a new image layer with the selection of channels\n",
    "\n",
    "Exercise:\n",
    "\n",
    "- List all channels.\n",
    "- Subset image with name `scan_region1` with the selection of channels (  `[ \"DAPI\", \"CD45\", \"CD68\", \"CD14\" ]` ).\n",
    "- Add subsetted image to the SpatialData object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "sdata[ \"scan_region1\" ].c.data\n",
    "\n",
    "#sdata[ \"scan_region1\" ].c.data.tolist()\n",
    "labels = [ \"DAPI\", \"CD45\", \"CD68\", \"CD14\" ]\n",
    "\n",
    "array_channels = sdata[ \"scan_region1\" ].c.data\n",
    "label_to_index = {label: idx for idx, label in enumerate(array_channels)}\n",
    "indices = [label_to_index[label] for label in labels]\n",
    "\n",
    "from spatialdata.transformations import get_transformation\n",
    "\n",
    "transformations = get_transformation( sdata[ \"scan_region1\" ], get_all=True )\n",
    "\n",
    "sdata = hp.im.add_image_layer(\n",
    "    sdata,\n",
    "    arr = sdata[ \"scan_region1\" ].data[ indices ],\n",
    "    output_layer = \"scan_region1_subset\",\n",
    "    transformations=transformations,\n",
    "    c_coords = labels,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[ \"scan_region1\" ].c.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sdata[ \"scan_region1\" ].c.data.tolist()\n",
    "labels = [ \"DAPI\", \"CD45\", \"CD68\", \"CD14\" ]\n",
    "\n",
    "array_channels = sdata[ \"scan_region1\" ].c.data\n",
    "label_to_index = {label: idx for idx, label in enumerate(array_channels)}\n",
    "indices = [label_to_index[label] for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatialdata.transformations import get_transformation\n",
    "\n",
    "transformations = get_transformation( sdata[ \"scan_region1\" ], get_all=True )\n",
    "\n",
    "sdata = hp.im.add_image_layer(\n",
    "    sdata,\n",
    "    arr = sdata[ \"scan_region1\" ].data[ indices ],\n",
    "    output_layer = \"scan_region1_subset\",\n",
    "    transformations=transformations,\n",
    "    c_coords = labels,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "# # Create a local Dask cluster\n",
    "cluster = LocalCluster(\n",
    "     n_workers=4,              # Number of worker processes. Possible to increase to more workers, depending on available memory/cores\n",
    "     threads_per_worker=1,    # Number of threads per worker\n",
    "     memory_limit=\"32GB\",      # Memory limit per worker\n",
    " )\n",
    "\n",
    "# # Connect a Client to the cluster\n",
    "client = Client(cluster)\n",
    "\n",
    "# # Print the Dask dashboard link\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import harpy as hp\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from instanseg import InstanSeg\n",
    "\n",
    "# takes approx 6 minutes on macOS\n",
    "\n",
    "path_model = os.path.join( target_path, \"instanseg.pt\" )\n",
    "\n",
    "instanseg_fluorescence = torch.load( path_model, weights_only=False )\n",
    "instanseg_fluorescence = InstanSeg( model_type=instanseg_fluorescence, device=\"cpu\" )\n",
    "\n",
    "crd_segment = None # [ 12000, 14000, 44000, 46000 ]\n",
    "\n",
    "sdata = hp.im.segment(\n",
    "    sdata,\n",
    "    img_layer=\"scan_region1_subset\",\n",
    "    output_labels_layer=[\"labels_cells_instanseg\"],\n",
    "    output_shapes_layer=[\"shapes_cells_instanseg\"],\n",
    "    labels_layer_align=None,\n",
    "    depth=50,\n",
    "    model=hp.im.instanseg_callable,\n",
    "    # parameters passed to hp.im.instanseg_callable\n",
    "    output=\"cells\",\n",
    "    device=\"cpu\",\n",
    "    instanseg_model=path_model,  # load it in every worker, because torchscript model is not serializable\n",
    "    iou=True,\n",
    "    trim=False,\n",
    "    crd=crd_segment,\n",
    "    to_coordinate_system=\"region1\",\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [ \"DAPI\", \"CD45\", \"CD68\", \"CD14\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer= \"scan_region1\",\n",
    "    shapes_layer = \"shapes_cells_instanseg\",\n",
    "    channel=\"DAPI\",\n",
    "    to_coordinate_system=\"region1\",\n",
    "    vmin_img = 50,\n",
    "    vmax_img = 500,\n",
    "    alpha=0.5,\n",
    "    crd = [12000, 13000, 44000, 45000 ],\n",
    "    figsize = (8,8),\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer = \"scan_region1\",\n",
    "    shapes_layer = \"shapes_cells_instanseg\",\n",
    "    channel = \"CD45\",\n",
    "    to_coordinate_system = \"region1\",\n",
    "    vmin_img = 50,\n",
    "    vmax_img = 500,\n",
    "    alpha=0.2,\n",
    "    crd = [12000, 13000, 44000, 45000 ],\n",
    "    figsize = (8,8),\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer= \"scan_region1\",\n",
    "    shapes_layer = \"shapes_cells_instanseg\",\n",
    "    channel = \"CD68\",\n",
    "    to_coordinate_system = \"region1\",\n",
    "    vmin_img = 200,\n",
    "    vmax_img = 500,\n",
    "    alpha=0.4,\n",
    "    crd = [12000, 13000, 44000, 45000 ],\n",
    "    figsize = (8,8),\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer= \"scan_region1\",\n",
    "    shapes_layer = \"shapes_cells_instanseg\",\n",
    "    channel=\"CD14\",\n",
    "    to_coordinate_system=\"region1\",\n",
    "    vmin_img = 200,\n",
    "    vmax_img = 500,\n",
    "    alpha=0.2,\n",
    "    crd = [12000, 13000, 44000, 45000 ],\n",
    "    figsize = (8,8),\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from spatialdata import read_zarr\n",
    "#sdata = read_zarr( sdata.path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to extract all channels\n",
    "from spatialdata.transformations import get_transformation\n",
    "from spatialdata.transformations import Translation\n",
    "\n",
    "if crd_segment is not None:\n",
    "\n",
    "    transformations = get_transformation( sdata[ \"scan_region1\" ], get_all=True )\n",
    "    y_translation=transformations[ \"region1\" ].to_affine_matrix( input_axes=(\"y\", \"x\" ), output_axes=( \"y\", \"x\" ) )[ 0, 2 ]\n",
    "    x_translation=transformations[ \"region1\" ].to_affine_matrix( input_axes=(\"y\", \"x\" ), output_axes=( \"y\", \"x\" ) )[ 1, 2 ]\n",
    "    \n",
    "    array=sdata[ \"scan_region1\" ].data[ :, crd_segment[ 2 ]-y_translation: crd_segment[3]-y_translation, crd_segment[0]-x_translation: crd_segment[1]-x_translation ]\n",
    "    \n",
    "    sdata = hp.im.add_image_layer(\n",
    "        sdata,\n",
    "        arr=array.rechunk( 2048 ),\n",
    "        output_layer=\"scan_region1_crop\",\n",
    "        transformations={ \"region1\": Translation( axes = ( \"y\", \"x\" ), translation=[ crd_segment[2], crd_segment[0] ] ) },\n",
    "        c_coords=sdata[ \"scan_region1\" ].c.data,\n",
    "        overwrite=True,\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = sdata[ \"scan_region1\" ].c.data\n",
    "channels = channels[ channels!=\"DAPI\" ]\n",
    "channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: \n",
    "\n",
    "Use the segmentation mask (`labels_cells_instanseg`) to create the AnnData table with the intensities for every channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "sdata = hp.tb.allocate_intensity( \n",
    "    sdata,\n",
    "    img_layer= \"scan_region1\" if crd_segment is None else \"scan_region1_crop\",\n",
    "    labels_layer=\"labels_cells_instanseg\",\n",
    "    output_layer=\"table_intensities\",\n",
    "    channels=channels,\n",
    "    mode= \"sum\",\n",
    "    to_coordinate_system=\"region1\",\n",
    "    overwrite=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = hp.tb.allocate_intensity( \n",
    "    sdata,\n",
    "    img_layer= \"scan_region1\" if crd_segment is None else \"scan_region1_crop\",\n",
    "    labels_layer=\"labels_cells_instanseg\",\n",
    "    output_layer=\"table_intensities\",\n",
    "    channels=channels,\n",
    "    mode= \"sum\",\n",
    "    to_coordinate_system=\"region1\",\n",
    "    overwrite=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[ \"table_intensities\" ].to_df().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata=hp.tb.preprocess_proteomics(\n",
    "    sdata,\n",
    "    labels_layer=\"labels_cells_instanseg\",\n",
    "    table_layer=\"table_intensities\",\n",
    "    output_layer=\"table_intensities_prepocessed\",\n",
    "    size_norm=True,\n",
    "    overwrite=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[ \"table_intensities_prepocessed\" ].to_df().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "# Leiden clustering\n",
    "sdata = hp.tb.leiden(\n",
    "    sdata,\n",
    "    labels_layer=\"labels_cells_instanseg\",\n",
    "    table_layer=\"table_intensities_prepocessed\",\n",
    "    output_layer=\"table_intensities_leiden\",\n",
    "    calculate_umap=True,\n",
    "    calculate_neighbors=True,\n",
    "    n_pcs=17, # The number of principal components to use when calculating neighbors.\n",
    "    n_neighbors=35, # The number of neighbors to consider when calculating neighbors.\n",
    "    resolution=0.4,\n",
    "    rank_genes=True,\n",
    "    key_added=\"leiden\",\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# Plot UMAP\n",
    "sc.pl.umap(sdata.tables[\"table_intensities_leiden\"], color=[\"leiden\"], show=True)\n",
    "\n",
    "sc.pl.rank_genes_groups(\n",
    "    sdata.tables[\"table_intensities_leiden\"],\n",
    "    n_genes=8,\n",
    "    sharey=False,\n",
    "    show=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.pl.plot_shapes( \n",
    "    sdata,\n",
    "    img_layer=\"scan_region1\",\n",
    "    table_layer=\"table_intensities_leiden\",\n",
    "    shapes_layer=\"shapes_cells_instanseg\",\n",
    "    column=\"leiden\",\n",
    "    channel=\"DAPI\",\n",
    "    linewidth=0.2,\n",
    "    alpha=0.7,\n",
    "    figsize=( 8,8 ),\n",
    "    to_coordinate_system=\"region1\",\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from napari_spatialdata import Interactive\n",
    "\n",
    "#Interactive( sdata )\n",
    "sdata[ \"scan_region1\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FlowSOM clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a crop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatialdata import read_zarr\n",
    "\n",
    "sdata = read_zarr( sdata.path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatialdata import bounding_box_query\n",
    "\n",
    "se=bounding_box_query(\n",
    "    sdata[ \"scan_region1\" ],\n",
    "    axes = ( \"y\", \"x\" ),\n",
    "    min_coordinate=[ 42000, 11000 ],\n",
    "    max_coordinate=[ 44000, 13000 ],\n",
    "    target_coordinate_system = \"region1\",\n",
    "        )\n",
    "\n",
    "sdata[ \"scan_region1_flowsom_crop\" ] = se\n",
    "sdata.write_element(\n",
    "    \"scan_region1_flowsom_crop\", overwrite=True\n",
    "      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.pl.plot_image(\n",
    "    sdata,\n",
    "    img_layer=\"scan_region1_flowsom_crop\",\n",
    "    to_coordinate_system=\"region1\",\n",
    "    channel=\"DAPI\",\n",
    "    figsize=(5,5)\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = sdata[ \"scan_region1_flowsom_crop\" ].c.data\n",
    "channels = channels[ channels!=\"DAPI\" ]\n",
    "channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing before flowsom clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = hp.im.pixel_clustering_preprocess( \n",
    "    sdata,\n",
    "    img_layer=\"scan_region1_flowsom_crop\",\n",
    "    output_layer=\"scan_region1_flowsom_preprocessed\",\n",
    "    channels=channels,\n",
    "    overwrite=True,\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[ \"scan_region1_flowsom_preprocessed\" ].c.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.pl.histogram(\n",
    "    sdata,\n",
    "    img_layer=\"scan_region1_flowsom_crop\",\n",
    "    channel=\"CD68\",\n",
    "    bins=100,\n",
    "    fig_kwargs={\n",
    "        \"figsize\": (4, 4),\n",
    "    },\n",
    ")\n",
    "\n",
    "# smoothing is applied\n",
    "\n",
    "hp.pl.histogram(\n",
    "    sdata,\n",
    "    img_layer=\"scan_region1_flowsom_preprocessed\",\n",
    "    channel=\"CD68\",\n",
    "    bins=100,\n",
    "    fig_kwargs={\n",
    "        \"figsize\": (4, 4),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FlowSOM clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flowsom as fs\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "work_with_client = False\n",
    "\n",
    "if work_with_client:\n",
    "    # client example\n",
    "    cluster = LocalCluster(\n",
    "        n_workers=1,\n",
    "        threads_per_worker=10,\n",
    "    )\n",
    "\n",
    "    client = Client(cluster)\n",
    "else:\n",
    "    client = None\n",
    "\n",
    "batch_model = fs.models.BatchFlowSOMEstimator\n",
    "\n",
    "sdata, fsom, mapping = hp.im.flowsom(\n",
    "    sdata,\n",
    "    img_layer=[\"scan_region1_flowsom_preprocessed\"],\n",
    "    output_layer_clusters=[\n",
    "        \"scan_region_1_flowsom_clusters\",\n",
    "    ],  # we need output_cluster_layer and output_meta_cluster_layer --> these will both be labels layers\n",
    "    output_layer_metaclusters=[\n",
    "        \"scan_region_1_flowsom_metaclusters\",\n",
    "    ],\n",
    "    n_clusters=20,\n",
    "    random_state=111,\n",
    "    chunks=512,\n",
    "    client=client,\n",
    "    model=batch_model,\n",
    "    num_batches=10,\n",
    "    xdim=10,\n",
    "    ydim=10,\n",
    "    z_score=True,\n",
    "    z_cap=3,\n",
    "    persist_intermediate=True,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = hp.tb.cluster_intensity(\n",
    "    sdata,\n",
    "    mapping=mapping,\n",
    "    img_layer=[\"scan_region1_flowsom_preprocessed\"],\n",
    "    labels_layer=[\"scan_region_1_flowsom_clusters\"],\n",
    "    to_coordinate_system=[\"region1\"],\n",
    "    output_layer=\"counts_clusters\",\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[ \"scan_region_1_flowsom_clusters\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatialdata import read_zarr\n",
    "\n",
    "sdata=read_zarr( sdata.path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatialdata import SpatialData\n",
    "from spatialdata import read_zarr\n",
    "\n",
    "# Due to weird bug in spatialdata plot, we need to use this temporary spatial data object\n",
    "sdata_temp = SpatialData()\n",
    "sdata_temp[  \"scan_region_1_flowsom_clusters\" ] = sdata[ \"scan_region_1_flowsom_clusters\" ]\n",
    "sdata_temp[  \"scan_region_1_flowsom_metaclusters\" ] = sdata[ \"scan_region_1_flowsom_metaclusters\" ]\n",
    "\n",
    "hp.pl.pixel_clusters(\n",
    "    sdata_temp,\n",
    "    labels_layer=\"scan_region_1_flowsom_clusters\",\n",
    "    figsize=(10, 10),\n",
    "    to_coordinate_system=\"region1\",\n",
    "    render_labels_kwargs={\"alpha\": 1},\n",
    ")\n",
    "\n",
    "hp.pl.pixel_clusters(\n",
    "    sdata_temp,\n",
    "    labels_layer=\"scan_region_1_flowsom_metaclusters\",\n",
    "    figsize=(10, 10),\n",
    "    to_coordinate_system=\"region1\",\n",
    "    render_labels_kwargs={\"alpha\": 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _metaclusters in [True, False]:\n",
    "    hp.pl.pixel_clusters_heatmap(\n",
    "        sdata,\n",
    "        table_layer=\"counts_clusters\",\n",
    "        figsize=(40, 16),\n",
    "        fig_kwargs={\"dpi\": 300},\n",
    "        linewidths=0.001,\n",
    "        metaclusters=_metaclusters,\n",
    "        z_score=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of the clusters:\n",
    "\n",
    "Cluster 9 -> SOX2 and SOX9 <br>\n",
    "Cluster 10 -> Podoplanin and LYVE1 <br>\n",
    "Cluster 2 -> MUC5AC, Pan-Cytokeratin, KRT8,... <br>\n",
    "Cluster 3 -> CD31, Caveolin <br>\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import squidpy as sq\n",
    "\n",
    "key_added = \"cluster_id\"\n",
    "\n",
    "adata = hp.tb.spatial_pixel_neighbors(\n",
    "    sdata,\n",
    "    labels_layer=\"scan_region_1_flowsom_metaclusters\",\n",
    "    key_added=key_added,\n",
    "    mode=\"most_frequent\",\n",
    "    grid_type=\"hexagon\",\n",
    "    size=20,\n",
    "    subset=None,\n",
    ")\n",
    "\n",
    "adata.uns[f\"{key_added}_nhood_enrichment\"][\"zscore\"] = np.nan_to_num(\n",
    "    adata.uns[f\"{key_added}_nhood_enrichment\"][\"zscore\"]\n",
    ")\n",
    "sq.pl.nhood_enrichment(adata, cluster_key=key_added, method=\"ward\", mode=\"zscore\", figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from napari_spatialdata import Interactive\n",
    "\n",
    "#Interactive( sdata )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training_env_14_4_25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
