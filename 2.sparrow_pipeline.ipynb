{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPArrOW pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will demonstrate how to use the SPArrOW pipeline to analyze targeted spatial transcriptomics data using the raw data from a Molecular Cartography ([Resolve Biosciences](https://resolvebiosciences.com/)) mouse liver WT dataset.\n",
    "\n",
    "When you make use of the SPArrOW pipeline tools, please cite [Pollaris et al. (2024)](https://www.biorxiv.org/content/biorxiv/early/2024/07/06/2024.07.04.601829.full.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import harpy as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in the data\n",
    "\n",
    "The dataset will be downloaded and cached using `pooch` via `harpy.dataset.registry`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from harpy.datasets.registry import get_registry\n",
    "\n",
    "unit_testing = True # Set to False during training\n",
    "\n",
    "# If path is set to None, example data will be downloaded in the default cache folder of your os. Set this to a custom path to change this behaviour.\n",
    "path = None\n",
    "# path = r\"c:\\tmp\" # Recommended on Windows\n",
    "# path = \"/staging/leuven/stg_00143/spatial_data_training\" # e.g. on HPC\n",
    "\n",
    "registry = get_registry(path = path)\n",
    "path_image = registry.fetch(\"transcriptomics/resolve/mouse/20272_slide1_A1-1_DAPI.tiff\")\n",
    "path_coordinates = registry.fetch(\"transcriptomics/resolve/mouse/20272_slide1_A1-1_results.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The OUTPUT_DIR is the directory where the SpatialData .zarr will be saved. Change it to your output directory of choice.\n",
    "OUTPUT_DIR =  tempfile.gettempdir()\n",
    "\n",
    "# OUTPUT_DIR = \"/staging/leuven/stg_00143/spatial_data_training/output_dir\" # e.g. on HPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_image.imread import imread\n",
    "\n",
    "# The DAPI image is read using dask image\n",
    "img = imread(path_image)\n",
    "\n",
    "# We print the image dimensions\n",
    "print('Image dimensions: ', img.shape)\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "from spatialdata import SpatialData, read_zarr\n",
    "\n",
    "# Create an empty SpatialData object\n",
    "sdata = SpatialData()\n",
    "\n",
    "# Set the path for the SpatialData .zarr\n",
    "zarr_path = os.path.join(OUTPUT_DIR, f\"sdata_{uuid.uuid4()}.zarr\")\n",
    "\n",
    "# Write the SpatialData to Zarr\n",
    "sdata.write(zarr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the Zarr data back as a SpatialData\n",
    "sdata = read_zarr(sdata.path)\n",
    "\n",
    "# Check if SpatialData is backed (i.e. stored on disk)\n",
    "sdata.is_backed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add the DAPI image to the SpatialData object\n",
    "sdata = hp.im.add_image_layer(\n",
    "    sdata, # The SpatialData object to which the new image layer will be added.\n",
    "    arr = img, # The array containing the image data to be added.\n",
    "    dims = ( \"c\", \"y\", \"x\" ), # A tuple specifying the dimensions of the image data\n",
    "    output_layer = \"raw_image\", # The name of the output layer where the image data will be stored.\n",
    "    overwrite = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can access the DAPI image like this:\n",
    "sdata[\"raw_image\"] # Or, alternatively: sdata.images[\"raw_image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a crop of the DAPI image\n",
    "hp.pl.plot_image(\n",
    "    sdata, \n",
    "    img_layer = \"raw_image\" , \n",
    "    crd = [0, 6432, 0, 6432], # The coordinates for the region of interest in the format (xmin, xmax, ymin, ymax). If None, the entire image is plotted.\n",
    "    figsize = (5,5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or, alternatively, via spatialdata-plot:\n",
    "import spatialdata_plot\n",
    "sdata.pl.render_images(\"raw_image\").pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Use the `Harpy` function `hp.pl.plot_image` to visualize another crop (e.g.: `x_min=2000`, `x_max=4000`, `y_min=1000`, `y_max=4000`). \n",
    "\n",
    "- Find the documentation for `hp.pl.plot_image` in the Harpy [readthedocs](https://harpy.readthedocs.io/en/latest/api.html). How would you save the plot to disk?\n",
    "\n",
    "- Bonus: `hp.pl.plot_image` is a wrapper function around `hp.pl.plot_shapes`. Read the documentation for `hp.pl.plot_shapes`. What does the `fig_kwargs` parameter do? Can you set the `dpi` to 300 for plot that will be saved?\n",
    "\n",
    "<details> \n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "hp.pl.plot_image( sdata, img_layer=\"raw_image\", crd = [ 2000, 4000, 1000, 4000 ], output = f'{OUTPUT_DIR}/plot.png', fig_kwargs={ \"dpi\":300 } )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Uncomment the following cell and explore the DAPI image in Napari. Try changing the contrast of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napari_spatialdata import Interactive\n",
    "\n",
    "# Interactive(sdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "- Bonus: Add DAPI as a multiscale image to the SpatialData object (tip: read the documentation).\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "# Add as multiscale image\n",
    "sdata=hp.im.add_image_layer(\n",
    "    sdata,\n",
    "    arr = array,\n",
    "    dims = ( \"c\", \"y\", \"x\" ),\n",
    "    output_layer = \"raw_image\",\n",
    "    scale_factors = [2, 2, 2, 2],\n",
    "    overwrite = True,\n",
    ")\n",
    "\n",
    "# Now it is a DataTree\n",
    "type(sdata[\"raw_image\"])  \n",
    "\n",
    "# Let's have a look at the dask array\n",
    "from harpy.image._image import _get_spatial_element\n",
    "se = _get_spatial_element(sdata, layer=\"raw_image\")\n",
    "se.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image preprocessing\n",
    "\n",
    "### 2.1 tiling correction and inpainting\n",
    "\n",
    "When working with Molecular Cartography data, the data is acquired in tiles that have uneven illumination and this can influence the downstream analysis greatly. Resolve Biosciences assured us this shouldn't impact the transcript counts, but we can check later on whether this is the case. This step is not necessary for most other imaging-based spatial transcriptomics technologies (Xenium, Merscope, ...), but you should plot the entire image to check whether you need this preprocessing step for your data. \n",
    "\n",
    "Harpy's tiling_correction() function can be used to correct for uneven illumination (using BaSiC on the back-end). The size of the imaging tiles needs to be known in order to run the function. The tile_size parameter is set to the tile size of Molecular Cartography (2144) by default.\n",
    "\n",
    "The tiling_correction() function also corrects for the black lines in between the tiles by using OpenCV's inpainting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing tiling correction\n",
    "sdata, flatfields = hp.im.tiling_correction(\n",
    "    sdata = sdata,\n",
    "    img_layer = \"raw_image\",\n",
    "    tile_size = 2144, # This is set to 2144 by default\n",
    "    output_layer = \"tiling_correction\",\n",
    "    crd = None,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# FIXME: It might be better to split up tiling_correction into two separate functions (illumination correction and inpainting) or it should be an argument in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the raw and corrected image side-by-side\n",
    "hp.pl.plot_image(sdata, img_layer=[ \"raw_image\", \"tiling_correction\" ], crd = [2000, 6000, 2000, 6000], figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 min-max filtering and contrast enhancing\n",
    "The next preprocessing steps include:\n",
    "\n",
    "- A min max filter can be added. The goal of this function is to substract background noise and make the borders of the nuclei/cells cleaner. It will also remove some debris. Note that if you set the size of the filter too small (smaller then the size of your nuclei), the function will create \"donuts\" (black spots in the center of your cells). If the size of the min max filter is chosen too big, not enough background will be subtracted. Generally, you want to aim for the average nucleus size and some fine-tuning may be necessary. For nuclei in Molecular Cartography data, 45-55 should be a great starting point.\n",
    "\n",
    "- We also recommend to perform contrast enhancement on your image. Harpy does this by using histogram equalization (CLAHE function). The amount of correction needed can be decided by adapting the contrast_clip value. If the image is already quite bright, 3.5 might be a good starting point. For dark images, you can go up to 10 or even more. Make sure at the end the whole image is evenly illuminated and no cells are dark in the background.\n",
    " \n",
    "If you think your data needs further image processing steps, you can perform these using the map_image function (see further)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform min max filtering\n",
    "sdata = hp.im.min_max_filtering(\n",
    "    sdata,\n",
    "    img_layer = \"tiling_correction\",\n",
    "    output_layer = \"min_max_filtered\",\n",
    "    size_min_max_filter = 45,\n",
    "    overwrite = True,\n",
    ")\n",
    "\n",
    "# Plot the min max filtered image\n",
    "hp.pl.plot_image(\n",
    "    sdata,\n",
    "    img_layer = \"min_max_filtered\",\n",
    "    crd = [2000,6000,2000,6000],\n",
    "    figsize = (5, 5),\n",
    ")\n",
    "\n",
    "# Perform contrast enhancement using CLAHE\n",
    "sdata = hp.im.enhance_contrast(\n",
    "    sdata,\n",
    "    img_layer = \"min_max_filtered\",\n",
    "    output_layer = \"clahe\",\n",
    "    contrast_clip = 3.5,\n",
    "    chunks = 20000,\n",
    "    overwrite = True\n",
    ")\n",
    "\n",
    "# Plot the contrast enhanced image\n",
    "hp.pl.plot_image(\n",
    "    sdata,\n",
    "    img_layer = \"clahe\",\n",
    "    crd = [2000,6000,2000,6000],\n",
    "    figsize = (5, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Change the `size_min_max_filter` parameter in `hp.im.min_max_filtering`. What do you see? Try some extreme values.\n",
    "- Change the `enhance_contrast` parameter in `hp.im.enhance_contrast`. What do you see? Try some extreme values.\n",
    "- Try image preprocessing on a different crop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Uncomment the following cell and explore the preprocessed images in Napari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interactive(sdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Custom distributed preprocessing of images using `hp.im.map_image` and `Dask`\n",
    "\n",
    "See https://docs.dask.org/en/stable/generated/dask.array.map_blocks.html and https://docs.dask.org/en/latest/generated/dask.array.map_overlap.html\n",
    "\n",
    "Set `blockwise==True` if you want to do distributed processing using `dask.array.map_blocks` or `dask.array.map_overlap`, set `blockwise==False` if your function is already distributed (e.g. when using `dask_image` filters https://image.dask.org/en/latest/dask_image.ndfilters.html.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "# Define your custom function\n",
    "def _my_dummy_function(image: NDArray, parameter: int | float )->NDArray:\n",
    "    # input (1,1,y,x)\n",
    "    # output (1,1,y,x)\n",
    "    print(f\"Type of the image is: {type(image)}\")\n",
    "    print(image.shape)\n",
    "    return image*parameter\n",
    "\n",
    "fn_kwargs = {\"parameter\": 2}\n",
    "\n",
    "# Apply custom function\n",
    "sdata = hp.im.map_image(\n",
    "    sdata,\n",
    "    func = _my_dummy_function,\n",
    "    fn_kwargs = fn_kwargs,\n",
    "    img_layer = \"raw_image\",\n",
    "    output_layer=\"dummy_image\",\n",
    "    chunks = 5000,\n",
    "    blockwise = False, # if blockwise == True --> input to _my_dummy_function is a numpy array of size chunks, else it is a Dask array (with chunksize chunks)\n",
    "    depth = 1000, # if blockwise == True, and depth specified, will use map_overlap instead of map_blocks for distributed processing\n",
    "    overwrite = True,\n",
    "    dtype = np.uint16,\n",
    "    meta = np.array((), dtype=np.uint16),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from harpy.image._image import _get_spatial_element\n",
    "\n",
    "_get_spatial_element(sdata, layer=\"raw_image\").data.compute()[ :, :10, :10 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_get_spatial_element(sdata, layer=\"dummy_image\").data.compute()[ :, :10,:10 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Adapt `my_dummy_function` so it accepts a new parameter, `parameter_2`. Now adapt `my_dummy_function` so the image is multiplied with (`parameter` + `parameter_2`)\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "def _my_dummy_function(image: NDArray, parameter: int | float, parameter_2: int | float )->NDArray:\n",
    "    # input (1,1,y,x)\n",
    "    # output (1,1,y,x)\n",
    "    print(f\"Type of the image is: {type(image)}\" )\n",
    "    print(image.shape)\n",
    "    return image*(parameter + parameter_2)\n",
    "\n",
    "fn_kwargs = {\"parameter\": 2 , \"parameter_2\": 2}\n",
    "\n",
    "sdata = hp.im.map_image(\n",
    "    sdata,\n",
    "    func = _my_dummy_function,\n",
    "    fn_kwargs = fn_kwargs,\n",
    "    img_layer = \"raw_image\",\n",
    "    output_layer=\"dummy_image\",\n",
    "    chunks = 5000,\n",
    "    blockwise = True, # if blockwise == True --> input to _my_dummy_function is a numpy array of size chunks, else it is a Dask array (with chunksize chunks)\n",
    "    depth = 1000, # if blockwise == True, and depth specified, will use map_overlap instead of map_blocks for distributed processing\n",
    "    overwrite = True,\n",
    "    dtype = np.uint16,\n",
    "    meta = np.array((), dtype=np.uint16),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Bonus: Run the cell where `hp.im.map_image` is called in debug mode. Set a breakpoint in `my_dummy_function`. Inspect the shape and type of `image` when you set `blockwise=True` or `blockwise=False`. Set the `depth` parameter to `100`. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Segmentation\n",
    "\n",
    "### 3.1 Nucleus segmentation\n",
    "\n",
    "To segment the nuclei, we here show an example using cellpose, a deep learning network based on a UNET architecture.\n",
    "\n",
    "Multiple parameters need to be given as an input to the cellpose algorithm. We recommend tuning these to achieve optimal segmentation quality (see https://cellpose.readthedocs.io/en/latest/settings.html). It is often a good idea to fine-tune the parameters on a crop of the image (especially when you only have CPU to work with).\n",
    " \n",
    "- diameter: Includes an estimate of the average nucleus diameter and needs to be given in pixels. If set to None, cellpose will try to estimate the diameter, but this might take a long time and is usually far off. As a guideline, you can use approx. 7 micrometer (in this case 50 pixels at 0.138 micrometer per pixel) for a standard nucleus, but this may vary depending on your specific tissue, sample...\n",
    "- device: Defines the device you want to work on. If you only have CPU, you can skip this input parameter.\n",
    "- flow_threshold: Indicates something about the shape of the masks. If you increase it, more masks with less round shapes will be accepted. Usually set between 0.6 and 0.95 (max. is 1). Lower this parameter if you start segmenting artefacts. Increase it if the segmentation misses some non-round cells.\n",
    "- mask_threshold: Indicates how many of the possible masks are kept. Decreasing the parameter will output more masks. Larger values will output less masks. Usually set between 0 and -6.\n",
    "- min_size: Indicates the minimum size of a nucleus.\n",
    "- model_type: If segmenting whole cells instead of nuclei, set this to 'cyto'. You can do this with and without a nucleus channel. When you want to include a nucleus channel for the segmentation, make sure your image is 3D and that the first channel contains the complete cell staining and the second one the nucleus channel (put the channel parameter to np.array([1,0]))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we rechunk on disk\n",
    "from spatialdata.transformations import get_transformation\n",
    "\n",
    "sdata=hp.im.add_image_layer(\n",
    "    sdata,\n",
    "    arr=sdata[ \"clahe\" ].data.rechunk( 2048 ),\n",
    "    transformations=get_transformation( sdata[ \"clahe\" ], get_all=True ),\n",
    "    output_layer = \"clahe\",\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ADVANCED: You can set up a local Dask distributed cluster for parallel computing. Once the cluster is created, a Dask Client is used to connect to it. \n",
    "The Dask dashboard link allows you to monitor cluster performance and task progress.\n",
    "\"\"\"\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "# # Create a local Dask cluster\n",
    "cluster = LocalCluster(\n",
    "     n_workers=8,              # Number of worker processes\n",
    "     threads_per_worker=1,    # Number of threads per worker\n",
    "     memory_limit=\"32GB\",      # Memory limit per worker\n",
    " )\n",
    "\n",
    "# # Connect a Client to the cluster\n",
    "client = Client(cluster)\n",
    "\n",
    "# # Print the Dask dashboard link\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from cellpose import models\n",
    "from harpy.image import cellpose_callable\n",
    "\n",
    "gpu = False\n",
    "device = \"cpu\"  # mps broken in cellpose (macOS), see https://github.com/MouseLand/cellpose/issues/1063\n",
    "\n",
    "# Perform nucleus segmentation\n",
    "sdata = hp.im.segment(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\", # The image layer in sdata to be segmented.\n",
    "    chunks=2048, #settings chunks=None would be equivalent to settings chunks=2048, as chunks on disk are 2048\n",
    "    depth=200,\n",
    "    model=cellpose_callable,\n",
    "    # parameters that will be passed to the callable _cellpose:\n",
    "    pretrained_model=\"nuclei\", # can also be \"cyto\", \"cyto3\", or a path to a fine-tuned cellpose model.\n",
    "    device=device,\n",
    "    diameter=50,\n",
    "    flow_threshold=0.9,\n",
    "    cellprob_threshold=-4,\n",
    "    output_labels_layer=\"segmentation_mask\",\n",
    "    output_shapes_layer=\"segmentation_mask_boundaries\",\n",
    "    crd=[ 2000,4000,2000,4000 ] if unit_testing else None,  # region to segment [x_min, xmax, y_min, y_max],\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# client.close() # ADVANCED: Uncomment this when using the Dask Client.\n",
    "# FIXME: Can we add support for both Cellpose 3 and 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot segmentation results\n",
    "hp.pl.plot_shapes(sdata, img_layer=\"clahe\", shapes_layer=\"segmentation_mask_boundaries\", figsize=(5,5), crd = [2000, 4000, 2000, 4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or via spatialdata-plot\n",
    "sdata.pl.render_images(\"clahe\").pl.render_labels(\"segmentation_mask\").pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To only visualize a crop using spatialdata-plot, we can't pass any coordinates, so but we can perform a bounding box query, and then plot the resulting `SpatialData` object.\n",
    "sdata_small = sdata.query.bounding_box(\n",
    "    min_coordinate=[2000, 2000], max_coordinate=[4000, 4000], axes=(\"x\", \"y\"), target_coordinate_system=\"global\"\n",
    ")\n",
    "\n",
    "sdata_small.pl.render_images(\"clahe\").pl.render_labels(\"segmentation_mask\", fill_alpha=0.5).pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Try changing segmentation parameters to see how they affect the results. Work on a crop of the image.\n",
    "- Go to the [documentation](https://spatialdata.scverse.org/projects/plot/en/latest/) of `spatialdata-plot`, and try to visualize the cell boundaries (i.e. the segmentation shapes layer)\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "sdata_small.pl.render_images(\"clahe\").pl.render_shapes(\"segmentation_mask_boundaries\", fill_alpha=1.0).pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Nucleus expansion\n",
    "In some cases, it may be useful to expand de nuclei segmentations to approximate the cell bodies. Note that this is not very precise and, while it increases the number of transcripts assigned to a cell, it also introduces more wrongly assigned transcripts (i.e. that actually belong to other cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand labels layer masks\n",
    "sdata = hp.im.expand_labels_layer(\n",
    "    sdata,\n",
    "    labels_layer=\"segmentation_mask\",\n",
    "    distance=10, # Number of pixels to expand\n",
    "    output_labels_layer=\"segmentation_mask_expanded\", # Creates a new labels layer\n",
    "    output_shapes_layer=\"segmentation_mask_expanded_boundaries\", # Creates a new shapes layer\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot nuclei masks vs expanded nuclei masks\n",
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\",\n",
    "    shapes_layer=[\"segmentation_mask_boundaries\", \"segmentation_mask_expanded_boundaries\"],\n",
    "    figsize=(10,10),\n",
    "    crd=[2000, 4000, 2000, 4000],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To only visualize a crop using spatialdata-plot, we can't pass any coordinates, so but we can perform a bounding box query, and then plot the resulting `SpatialData` object.\n",
    "sdata_small = sdata.query.bounding_box(\n",
    "    min_coordinate=[2000, 2000], max_coordinate=[4000, 4000], axes=(\"x\", \"y\"), target_coordinate_system=\"global\"\n",
    ")\n",
    "\n",
    "sdata_small.pl.render_images(\n",
    "    \"clahe\",\n",
    "    cmap=\"gray\",\n",
    ").pl.render_shapes(\n",
    "    \"segmentation_mask_boundaries\", \n",
    "    fill_alpha=0, \n",
    "    outline_width=0.3,\n",
    "    outline_color='cyan',\n",
    "    outline_alpha=1,\n",
    ").pl.render_shapes(\n",
    "    \"segmentation_mask_expanded_boundaries\",\n",
    "    fill_alpha=0, \n",
    "    outline_width=0.3,\n",
    "    outline_color='orange', \n",
    "    outline_alpha=1,\n",
    ").pl.show(\n",
    "    title=\"segmentation masks (cyan) vs. expanded segmentation masks (orange)\",\n",
    "    figsize=(10, 10),\n",
    "    colorbar=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Allocating  the transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4.1 Creating the count matrix\n",
    "In this step we\n",
    "- load in the transcipts: in the case of Molecular Cartography, we can use `hp.io.read_resolve_transcripts`. If no specific loader exist for your data type, you can use the general `hp.io.read_transcripts` function.\n",
    "- allocate the transcripts to the correct cell. This allocation step creates the count matrix saved in an [anndata](https://anndata.readthedocs.io/en/stable/) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Molecular Cartography transcript data as a points layer\n",
    "sdata = hp.io.read_resolve_transcripts(\n",
    "    sdata, \n",
    "    output_layer=\"transcripts\", # Name of the points layer of the SpatialData object to which the transcripts will be added.\n",
    "    path_count_matrix=path_coordinates, # Path to the file containing the transcripts information specific to Molecular Cartography.\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# Allocate transcripts to cells based on the segmentation masks\n",
    "sdata = hp.tb.allocate(\n",
    "    sdata=sdata,\n",
    "    labels_layer=\"segmentation_mask\", # The labels layer (i.e. segmentation mask) in `sdata` to be used to allocate the transcripts to cells.\n",
    "    points_layer=\"transcripts\", # The points layer in `sdata` that contains the transcripts.\n",
    "    output_layer=\"table_transcriptomics\", # The table layer in `sdata` in which to save the AnnData object with the transcripts counts per cell.\n",
    "    update_shapes_layers=False,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the new points layer\n",
    "print(type(sdata.points[\"transcripts\"]))\n",
    "sdata.points[\"transcripts\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the new table layer\n",
    "display(sdata.tables[\"table_transcriptomics\"])\n",
    "\n",
    "print('Number of cells: ', len(sdata.tables[\"table_transcriptomics\"].obs.index))\n",
    "print('Number of genes: ', len(sdata.tables[\"table_transcriptomics\"].var.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the count matrix in the new table layer\n",
    "sdata.tables[\"table_transcriptomics\"].to_df().head() # On large count matrices, calls to .to_df() should be avoided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the var of the new table layer\n",
    "sdata.tables[\"table_transcriptomics\"].var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the obs of the new table layer\n",
    "sdata.tables[\"table_transcriptomics\"].obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the spatial coordinates stored in obsm\n",
    "sdata.tables[\"table_transcriptomics\"].obsm['spatial'][:5] # x,y,(z) coordinates of cell centre (calculated based on mean transcripts location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the spatialdata_attrs in .uns to check the instance_key and region_key\n",
    "sdata.tables[\"table_transcriptomics\"].uns['spatialdata_attrs']\n",
    "\n",
    "# NOTE: The AnnData object that is added as a table layer is annotated by the labels layer \"segmentation_mask\". The instance_key ('cell_ID') matches the labels in \"segmentation_mask\".\n",
    "# NOTE: Tables of a SpatialData object can be theoretically be annotated by a labels layer, a shapes layer or a points layer, but tables generated by the Harpy pipeline will always use a labels layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "print('Number of cells in table: ', len(sdata.tables[\"table_transcriptomics\"].obs))\n",
    "print('Number of segmentation masks in labels layer: ', len(da.unique(sdata.labels[\"segmentation_mask\"].data).compute()) - 1) # We subtract 1 because 0 is also a value, but this corresponds to the background.\n",
    "print('Number of segmentation boundaries in shapes layer: ', len(sdata.shapes[\"segmentation_mask_boundaries\"]))\n",
    "\n",
    "# NOTE: Not all segmentation masks are included in the table layer \"table_transcriptomics\". This is because not all cells could be assigned transcripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Run .compute() on the sdata.points['transcripts'] layer. What is the data type of the resulting object? What is the data type of the original points layer?\n",
    "- Have a look at https://docs.dask.org/en/stable/dataframe.html to understand the difference between both data types.\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "from IPython.display import display\n",
    "\n",
    "display(sdata[\"transcripts\"].compute().head())\n",
    "display(type(sdata[\"transcripts\"].compute())) \n",
    "display(type(sdata[\"transcripts\"])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Bonus: Extract transformation from the points layer \"transcripts\" using `spatialdata.transformations.get_transformation`. See https://spatialdata.scverse.org/en/stable/generated/spatialdata.transformations.get_transformation.html\n",
    "- Bonus: Now extract the transformation from the labels layer \"segmentation_mask\" and for the image layer \"clahe\".\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "from IPython.display import display\n",
    "from spatialdata.transformations import get_transformation\n",
    "\n",
    "display(get_transformation(sdata[\"transcripts\"]))\n",
    "display(get_transformation(sdata[\"segmentation_mask\"]))\n",
    "display(get_transformation(sdata[\"clahe\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Visualize the points layer and the labels layer using napari-spatialdata. Convince yourself they are registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive(sdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Visualizing gene expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the expression of the Axl gene using hp.pl.polt_shapes()\n",
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\",\n",
    "    shapes_layer=\"segmentation_mask_boundaries\",\n",
    "    figsize=(5,5),\n",
    "    crd=[2000, 4000, 2000, 4000],\n",
    "    table_layer=\"table_transcriptomics\",\n",
    "    column=\"Axl\",\n",
    ")\n",
    "\n",
    "# NOTE: In Harpy/SpatialData there is a connection between tables, shapes and labels via the region_key and the cell id, which allows us to plot a certain column of a table spatially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the expression of the Axl gene using spatialdata-plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "gene_name = \"Axl\"\n",
    "\n",
    "sdata_small = sdata.query.bounding_box(\n",
    "    min_coordinate=[2000, 2000], max_coordinate=[4000, 4000], axes=(\"x\", \"y\"), target_coordinate_system=\"global\"\n",
    ")\n",
    "\n",
    "sdata_small.pl.render_labels(\"segmentation_mask\", color=gene_name, method=\"datashader\", fill_alpha=0.5, table_name=\"table_transcriptomics\").pl.show(\n",
    "    coordinate_systems=\"global\", ax=ax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore gene expression interactively using napari-spatialdata\n",
    "\n",
    "# Interactive(sdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Use `hp.pl.plot_shapes` to plot the expression of some other genes that are in the dataset.\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "display(sdata[\"table_transcriptomics\"].var)\n",
    "\n",
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\",\n",
    "    shapes_layer=\"segmentation_mask_boundaries\",\n",
    "    figsize=(5,5),\n",
    "    crd=[2000, 4000, 2000, 4000],\n",
    "    table_layer=\"table_transcriptomics\",\n",
    "    column=\"Vwf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "Use `napari-spatialdata` to visualize the gene expression of the gene `Axl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive(sdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4.3 Transcript quality\n",
    "After we have created the anndata object, we want to check the transcript quality. First we create a plot to check if the transcript density is similar across the whole tissue. If this isn't the case, there can be multiple biological or technical reasons. Note that gene panel choices can also have an influence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transcript density image\n",
    "sdata = hp.im.transcript_density(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\", # The layer of the SpatialData object used for determining image boundary.\n",
    "    points_layer=\"transcripts\", # The layer name that contains the transcript data points, by default \"transcripts\".\n",
    "    output_layer=\"transcript_density\", # The name of the output image layer\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot transcript density\n",
    "hp.pl.plot_image(sdata, img_layer = [\"clahe\", \"transcript_density\"], figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot transcript and cell density using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Get cell coordinates\n",
    "df_cells = pd.DataFrame(sdata.tables[\"table_transcriptomics\"].obsm['spatial'], columns=['x', 'y'])\n",
    "\n",
    "# Get transcript coordinates\n",
    "df_transcripts = sdata.points[\"transcripts\"].compute()\n",
    "\n",
    "# Create a side-by-side plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(30, 15))\n",
    "\n",
    "# Plot cell density (left)\n",
    "h1 = axs[0].hexbin(\n",
    "    df_cells[\"x\"], df_cells[\"y\"],\n",
    "    gridsize=100,\n",
    "    cmap=\"viridis\",\n",
    "    linewidths=0.2,\n",
    "    edgecolors='face',\n",
    ")\n",
    "fig.colorbar(h1, ax=axs[0], label='Cell Count')\n",
    "axs[0].set_title(\"Cell Density (Hexbin)\")\n",
    "axs[0].set_xlabel(\"x\")\n",
    "axs[0].set_ylabel(\"y\")\n",
    "axs[0].axis(\"equal\")\n",
    "axs[0].invert_yaxis()\n",
    "\n",
    "# Plot transcript density (right)\n",
    "h2 = axs[1].hexbin(\n",
    "    df_transcripts[\"x\"], df_transcripts[\"y\"],\n",
    "    gridsize=500,\n",
    "    cmap=\"viridis\",\n",
    "    linewidths=0.2,\n",
    "    edgecolors='face',\n",
    ")\n",
    "fig.colorbar(h2, ax=axs[1], label='Transcript Count')\n",
    "axs[1].set_title(f\"Transcript Density (Hexbin)\")\n",
    "axs[1].set_xlabel(\"x\")\n",
    "axs[1].set_ylabel(\"y\")\n",
    "axs[1].axis(\"equal\")\n",
    "axs[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# FIXME: We could (should) include these plotting functionality in harpy? Maybe also an option to plot hexbin for column variables in table layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of transcripts\n",
    "print('Number of transcripts in points layer: ', len(sdata.points[\"transcripts\"]))\n",
    "print('Number of transcripts assigned to cells: ', sdata.tables[\"table_transcriptomics\"].X.sum())\n",
    "print('Percentage of transcripts kept: ', ((sdata.tables[\"table_transcriptomics\"].X.sum())/len(sdata.points[\"transcripts\"]))*100)\n",
    "\n",
    "# NOTE: Only a fraction of transcripts are assigned to cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of genes\n",
    "print('Number of genes in points layer: ', sdata.points['transcripts'].compute()['gene'].nunique())\n",
    "print('Number of genes found in cells: ', len(sdata.tables[\"table_transcriptomics\"].var.index))\n",
    "\n",
    "# NOTE: In general, we don't want to lose any genes, but this may happen if they have a low abundance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which genes are not found in cells\n",
    "genes_not_found_in_cells = set(sdata.points['transcripts'].compute()['gene'].unique()) - set(sdata.tables[\"table_transcriptomics\"].var.index)\n",
    "\n",
    "print(\"Number of genes not found in cells: \", len(genes_not_found_in_cells))\n",
    "print(\"Genes not found in cells:\", genes_not_found_in_cells)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the transcript points table to a DataFrame\n",
    "df_transcripts = sdata.points[\"transcripts\"].compute()\n",
    "\n",
    "# Filter and count transcripts for Ms4a7\n",
    "gene_name = \"Ms4a7\"\n",
    "count = (df_transcripts[\"gene\"] == gene_name).sum()\n",
    "\n",
    "print(f\"Number of transcripts for {gene_name}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse and visualize the proportion of transcripts that could not be assigned to a cell during allocation step.\n",
    "\n",
    "df_analyse_genes_left_out = hp.pl.analyse_genes_left_out(\n",
    "    sdata,\n",
    "    labels_layer=\"segmentation_mask\",\n",
    "    table_layer=\"table_transcriptomics\",\n",
    "    points_layer=\"transcripts\",\n",
    ")\n",
    "\n",
    "# NOTE: In general we see a downward trend. The more a gene is measured, the less it is located in cells (in ratio). \n",
    "# NOTE: The function also prints the ten genes with the highest proportion of transcripts filtered out. If a lot of these genes are markers for the same cell type, you will want to find out why this is happening (bad staining, large cell body compared to nucleus, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect analyse_genes_left_out() output table\n",
    "df_analyse_genes_left_out.sort_values(by=\"proportion_kept\", ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Processing the AnnData table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Filtering and Normalization\n",
    "\n",
    "The next steps are performed to further process the AnnData object:\n",
    "\n",
    "- QC metrics are calculated.\n",
    "- Filtering: cells with fewer than a certain amount of counts (e.g. 10) and genes occuring in fewer than a certain amount of cells (e.g. 5) are filtered out.\n",
    "- Normalization: for small gene panels (<500), we recommend to normalize the data based on the size of the segmented object (`size_norm=True`). For transcriptome-wide methods, we recommend library size normalization based on the total expression (`size_norm=False`). \n",
    "- log1p-transformation of the expression data (y=ln(1+x)).\n",
    "- Scale data to unit variance and zero mean. The scaling is capped at `max_value_scale`.\n",
    "- PCA calculation\n",
    "\n",
    "\n",
    "The last plot shows the size of the nucleus related to the counts. When working with whole cells, if there are some really big cells with really low counts, they are probably not real cells and you should filter based on max size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform preprocessing.\n",
    "sdata = hp.tb.preprocess_transcriptomics(\n",
    "    sdata,\n",
    "    labels_layer=\"segmentation_mask\",\n",
    "    table_layer=\"table_transcriptomics\",\n",
    "    output_layer=\"table_transcriptomics_preprocessed\", # write results to a new slot, we could also write to the same slot (when passing overwrite==True).\n",
    "    min_counts=10,\n",
    "    min_cells=5,\n",
    "    size_norm=True,\n",
    "    highly_variable_genes=False,  # If True, will only retain highly variable genes. This can be used for transcriptome-wide methods.\n",
    "    max_value_scale=10, # The maximum value to which data will be scaled\n",
    "    n_comps=50, # Number of principal components to calculate.\n",
    "    overwrite=True,\n",
    "    update_shapes_layers=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect preprocessed table\n",
    "sdata.tables[ \"table_transcriptomics_preprocessed\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect expression values\n",
    "sdata.tables[\"table_transcriptomics_preprocessed\"].to_df().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check mean expression values per gene\n",
    "sdata.tables[\"table_transcriptomics_preprocessed\"].to_df().mean(axis=0).head() # mean ~ 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check standard deviation of expression values per gene\n",
    "sdata.tables[\"table_transcriptomics_preprocessed\"].to_df().std(axis=0).head() # std ~ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check max expression value per gene\n",
    "sdata.tables[\"table_transcriptomics_preprocessed\"].to_df().max(axis=0).head() # max ~ 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect obs of preprocessed table\n",
    "sdata.tables[\"table_transcriptomics_preprocessed\"].obs.head()\n",
    "\n",
    "# n_genes_by_counts: The number of genes with at least 1 count in a cell\n",
    "# log1p_n_genes_by_counts: log1p-transformed n_genes_by_counts\n",
    "# total_counts: Total number of counts for a cell\n",
    "# log1p_total_counts: log1p-transformed total_counts\n",
    "# pct_counts_in_top_2_genes: The percentage of the total gene expression in each cell that comes from the top 2 most highly expressed genes in that cell\n",
    "# pct_counts_in_top_5_genes: The percentage of the total gene expression in each cell that comes from the top 5 most highly expressed genes in that cell \n",
    "# n_counts: Number of counts in a cell\n",
    "# shapeSize: Area of cell (in pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sum of transcript counts\n",
    "(sdata.tables[\"table_transcriptomics\"].to_df()).sum(axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of genes\n",
    "(sdata.tables[\"table_transcriptomics\"].to_df()>0).sum(axis = 1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect var of preprocessed table\n",
    "sdata.tables[\"table_transcriptomics_preprocessed\"].var.head()\n",
    "\n",
    "# n_cells_by_counts: Number of cells this gene is found in\n",
    "# mean_counts: Mean counts over all cells\n",
    "# log1p_mean_counts: log1p of mean_counts\n",
    "# pct_drop_by_counts: Percentage of cells this gene does not appear in\n",
    "# total_counts: Total number of counts for a gene\n",
    "# logp_total_counts: log1p of total_counts\n",
    "# n_cells: Number of cells this gene is found in\n",
    "# mean:\n",
    "# std:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot preprocessing QC plots\n",
    "hp.pl.preprocess_transcriptomics(\n",
    "    sdata,\n",
    "    table_layer=\"table_transcriptomics_preprocessed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additionally, plot a histogram of segmentation mask areas\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.histplot(sdata.tables[\"table_transcriptomics_preprocessed\"].obs[\"shapeSize (pixels)\"], kde=False)\n",
    "plt.title(\"Area of Segmentation Masks\")\n",
    "plt.xlabel(\"shapeSize\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot total counts\n",
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\",\n",
    "    table_layer=\"table_transcriptomics_preprocessed\",\n",
    "    column=\"total_counts\",\n",
    "    shapes_layer=\"segmentation_mask_boundaries\",\n",
    "    crd=[2000, 4000, 2000, 4000],\n",
    "    figsize=(8,8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter cells on size\n",
    "sdata = hp.tb.filter_on_size(\n",
    "    sdata,\n",
    "    labels_layer=\"segmentation_mask\",\n",
    "    table_layer=\"table_transcriptomics_preprocessed\",\n",
    "    output_layer=\"table_transcriptomics_filter\",\n",
    "    min_size=500, # Minimum cell size\n",
    "    max_size=100000, # Maximum cell size\n",
    "    update_shapes_layers=True,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.pl.plot_shapes(\n",
    "    sdata, \n",
    "    img_layer=\"clahe\", \n",
    "    shapes_layer=\"segmentation_mask_boundaries\", \n",
    "    shapes_layer_filtered=\"filtered_size_segmentation_mask_boundaries\", # Filtered cells will be plotted in red.\n",
    "    figsize=(5,5), \n",
    "    crd = [2000, 4000, 2000, 4000]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Clustering\n",
    "\n",
    "This function performs the neighborhood analysis and the leiden clustering and the UMAP calculations using standard scanpy functions.\n",
    "\n",
    "You need to define the following parameters:\n",
    "- The amount of PC's used: Between 15-20 is a good starting point (based on the plot of PCs).\n",
    "- The amount of neighbors used: 35 is generally a good value. In general, less neighbors means more spread, more means everything is tighter.\n",
    "- Cluster resolution.\n",
    "\n",
    "It returns the UMAP and marker gene list per cluster, that can be looked at for finding celltypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "# Leiden clustering\n",
    "sdata = hp.tb.leiden(\n",
    "    sdata,\n",
    "    labels_layer=\"segmentation_mask\",\n",
    "    table_layer=\"table_transcriptomics_filter\",\n",
    "    output_layer=\"table_transcriptomics_clustered\",\n",
    "    calculate_umap=True,\n",
    "    calculate_neighbors=True,\n",
    "    n_pcs=17, # The number of principal components to use when calculating neighbors.\n",
    "    n_neighbors=35, # The number of neighbors to consider when calculating neighbors.\n",
    "    resolution=0.8,\n",
    "    rank_genes=True,\n",
    "    key_added=\"leiden\",\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# Plot UMAP\n",
    "sc.pl.umap(sdata.tables[\"table_transcriptomics_clustered\"], color=[\"leiden\"], show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot clusters spatially\n",
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\",\n",
    "    table_layer=\"table_transcriptomics_clustered\",\n",
    "    column=\"leiden\",\n",
    "    shapes_layer=\"segmentation_mask_boundaries\",\n",
    "    alpha=1.0,\n",
    "    linewidth=0,\n",
    "    # crd=[2000, 4000, 2000, 4000]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot other variables on the UMAP as well\n",
    "from matplotlib.pyplot import rc_context\n",
    "color_vars = [\n",
    "    \"n_counts\",\n",
    "    \"n_genes_by_counts\",\n",
    "    \"shapeSize\",\n",
    "    \"Glul\",\n",
    "    \"leiden\",\n",
    "]\n",
    "with rc_context({\"figure.figsize\": (3, 3)}):\n",
    "    sc.pl.umap(sdata.tables[\"table_transcriptomics_clustered\"], color=color_vars, ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.rank_genes_groups(sdata.tables[\"table_transcriptomics_clustered\"], n_genes=8, sharey=False, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "Change the parameters of `hp.tb.leiden`. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from napari_spatialdata import Interactive\n",
    "\n",
    "#del sdata.tables[\"table_transcriptomics_clustered\"].uns[\"leiden_colors\"]\n",
    "#Interactive(sdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for fun, also plot via spatialdataplot\n",
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "column = \"leiden\"\n",
    "\n",
    "adata = sdata.tables[ \"table_transcriptomics_clustered\" ]\n",
    "\n",
    "#cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\n",
    "#                    \"new_map\",\n",
    "#                    adata.uns[column + \"_colors\"],\n",
    "#                    N=len(adata.uns[column + \"_colors\"]),\n",
    "#                )\n",
    "\n",
    "sdata_small = sdata.query.bounding_box(\n",
    "    min_coordinate=[2000, 2000], max_coordinate=[4000, 4000], axes=(\"x\", \"y\"), target_coordinate_system=\"global\"\n",
    ")\n",
    "\n",
    "sdata_small.pl.render_labels(\"segmentation_mask\", color=column, cmap=None, method=\"datashader\", fill_alpha=1, table_name= \"table_transcriptomics_clustered\").pl.show(\n",
    "    coordinate_systems=\"global\", ax=ax\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Cell type annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 Annotating clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we specify a dictionary with marker genes for some interesting cell types.\n",
    "marker_genes_dict = {\n",
    "    'LSEC': ['Stab2', 'Pecam1'],\n",
    "    'HepatocytesPortal': ['Pck1', 'Hal', 'Sds'],\n",
    "    'HepatocytesCentral': ['Cyp2e1', 'Glul', 'Lgr5'],\n",
    "    'Cholangiocytes': ['Spp1', 'Sox9','Epcam'],\n",
    "    'B_cells': ['Ccr7', 'Cd19', 'Cd79a'],\n",
    "    'Kuppfer_cells': ['Axl', 'Cd5l', 'Clec4f'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can visualize the expression of these marker genes in the Leiden clusters using a scanpy's matrix plot.\n",
    "sc.pl.matrixplot(\n",
    "    sdata.tables[\"table_transcriptomics_clustered\"], \n",
    "    var_names=marker_genes_dict, \n",
    "    groupby=\"leiden\", \n",
    "    cmap=\"Blues\",\n",
    "    standard_scale=\"var\",\n",
    "    colorbar_title=\"column scaled\\nexpression\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use a dot plot\n",
    "sc.pl.dotplot(\n",
    "    sdata.tables[\"table_transcriptomics_clustered\"], \n",
    "    var_names=marker_genes_dict, \n",
    "    groupby=\"leiden\", \n",
    "    cmap=\"Blues\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The heatmap plot does not collapse the cells into a single average value per cluster\n",
    "sc.pl.heatmap(\n",
    "    sdata.tables[\"table_transcriptomics_clustered\"], \n",
    "    var_names=marker_genes_dict, \n",
    "    groupby=\"leiden\", \n",
    "    cmap=\"viridis\", \n",
    ")\n",
    "\n",
    "# For more visualization options, see the scanpy documentation: https://scanpy.readthedocs.io/en/stable/tutorials/plotting/core.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.2 Annotating cells using sc.tl.score_genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use a marker gene list and score cells for each cell type using those markers via scanpy's `sc.tl.score_genes` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Download annotation file from registry\n",
    "path_mg = registry.fetch(\"transcriptomics/resolve/mouse/markerGeneListMartinNoLow.csv\")\n",
    "\n",
    "df = pd.read_csv(path_mg, index_col=0, delimiter=\",\")\n",
    "df.columns = df.columns.str.replace(' ', '_', regex=False) # whitespaces no longer allowed since spatialdata>=0.3.0\n",
    "\n",
    "# Inspect annotation file containing markers\n",
    "display(df.head()) # This is one-hot encoded matrix with cell types listed in the first row, and marker genes in the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate cells\n",
    "sdata, celltypes_scored, celltypes_all = hp.tb.score_genes(\n",
    "    sdata,\n",
    "    labels_layer=\"segmentation_mask\",\n",
    "    table_layer=\"table_transcriptomics_clustered\",\n",
    "    output_layer=\"table_transcriptomics_score_genes\",\n",
    "    path_marker_genes=df, # path_marker_genes can also be a dataframe\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect new table layer\n",
    "sdata[\"table_transcriptomics_score_genes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect new table layer obs\n",
    "sdata.tables[\"table_transcriptomics_score_genes\"].obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cell type annotations on UMAP\n",
    "sc.pl.umap(sdata.tables[\"table_transcriptomics_score_genes\"], color=\"annotation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cell type annotations spatially\n",
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    column=\"annotation\",\n",
    "    img_layer=\"clahe\",\n",
    "    table_layer= \"table_transcriptomics_score_genes\",\n",
    "    shapes_layer=\"segmentation_mask_boundaries\",\n",
    "    linewidth=0,\n",
    "    alpha=0.7,\n",
    "    crd=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's inspect the cell type counts and percentages\n",
    "counts = sdata.tables[\"table_transcriptomics_score_genes\"].obs['annotation'].value_counts()\n",
    "percentages = sdata.tables[\"table_transcriptomics_score_genes\"].obs['annotation'].value_counts(normalize=True) * 100\n",
    "\n",
    "cluster_summary = pd.DataFrame({\n",
    "    'count': counts,\n",
    "    'percentage': percentages.round(2)\n",
    "})\n",
    "\n",
    "print(cluster_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Squidpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.1 Constructing spatial graphs\n",
    "The spatial graph is a network where each node represents an observation (spot/cell) and edges signify neighborhood relationships (calculated based on the spatial coordiantes of the observations). This graph is useful for various analyses, such as neighborhood enrichment and calcualting spatial statistics such as spatial autocorrelation.\n",
    "\n",
    "We use squidpy.gr.spatial_neighbors to compute the spatial neighbors graph in this non-grid dataset, setting coord_type=\"generic\", and n_neighs=6 to specify that each observation should have 6 neighbors (this is called K-nearest neighbors(KNN)). We could also calculate neighbor relationships based on a radius around each cell or we could set delaunay=True to apply Delaunay triangulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try calculating spatial neighbors using Squidpy\n",
    "import squidpy as sq\n",
    "\n",
    "sq.gr.spatial_neighbors(\n",
    "    adata=sdata[\"table_transcriptomics_score_genes\"], \n",
    "    coord_type=\"generic\", # Set to 'generic' for targeted spatial transcriptomics\n",
    "    n_neighs=6, # Only used when delaunay = False\n",
    "    radius=None, # To compute the neighbors based on the radius\n",
    "    delaunay=False, # Whether to compute the graph from Delaunay triangulation\n",
    "    set_diag=False, # Whether to set the diagonal of the connectivity matrix to 1 (i.e. whether cells should be considered neighbors of themselves).\n",
    "    key_added=\"KNN\"\n",
    ")\n",
    "\n",
    "sdata.tables[\"table_transcriptomics_score_genes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUT, this is not yet backed to the zarr store!\n",
    "from spatialdata import read_zarr\n",
    "\n",
    "sdata = read_zarr(sdata.path)\n",
    "\n",
    "sdata.tables[\"table_transcriptomics_score_genes\"]\n",
    "\n",
    "# NOTE: .uns[\"spatial_neighbors\"], .obsp[\"spatial_connectivities\"] and .obsp[\"spatial_distances\"] are no longer in table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try calculating the spatial neighbors again, but we'll make sure the new table is backed to the zarr store by using hp.tb.add_table_layer().\n",
    "from harpy.utils._keys import _REGION_KEY\n",
    "\n",
    "sq.gr.spatial_neighbors(\n",
    "    adata=sdata[\"table_transcriptomics_score_genes\"], \n",
    "    coord_type=\"generic\", # Set to 'generic' for targeted spatial transcriptomics\n",
    "    n_neighs=6, # Only used when delaunay = False\n",
    "    radius=None, # To compute the neighbors based on the radius\n",
    "    delaunay=False, # Whether to compute the graph from Delaunay triangulation\n",
    "    set_diag=False, # Whether to set the diagonal of the connectivity matrix to 1 (i.e. whether cells should be considered neighbors of themselves).\n",
    "    key_added=\"KNN\"\n",
    ")\n",
    "\n",
    "region = sdata[\"table_transcriptomics_score_genes\"].obs[_REGION_KEY].cat.categories.to_list()\n",
    "\n",
    "sdata = hp.tb.add_table_layer(\n",
    "    sdata,\n",
    "    adata=sdata.tables[\"table_transcriptomics_score_genes\"],\n",
    "    output_layer=\"table_transcriptomics_squidpy\",\n",
    "    region=region, # A list of regions to associate with the table data. Typically this is all unique elements in adata.obs[_REGION_KEY].\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect spatial connectivities of first 10 rows and colomns\n",
    "sdata.tables['table_transcriptomics_squidpy'].obsp['KNN_connectivities'].toarray()[6:10,6:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect spatial distances\n",
    "sdata.tables['table_transcriptomics_squidpy'].obsp['KNN_distances'].toarray()[6:10,6:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect number of neighbors (for first 10 cells)\n",
    "sdata.tables['table_transcriptomics_squidpy'].obsp['KNN_connectivities'].toarray().sum(axis=1)[0:10] # sums across the columns for each row\n",
    "\n",
    "# NOTE: Every cell has exactly 6 neighbors when using n_neigh=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect for every cell how many cells have it as a neighbor (for first 10 cells)\n",
    "sdata.tables['table_transcriptomics_squidpy'].obsp['KNN_connectivities'].toarray().sum(axis=0)[0:10] # sums across the rows for each column\n",
    "\n",
    "# NOTE: Not every cell is a neighbor of exactly 6 cells when using n_neigh=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.pl.spatial_scatter(\n",
    "    sdata.tables[\"table_transcriptomics_squidpy\"],\n",
    "    shape=None,\n",
    "    color=\"annotation\",\n",
    "    connectivity_key=\"KNN_connectivities\",\n",
    "    size=30,\n",
    "    figsize=(15,15),\n",
    "    legend_loc='best',\n",
    "    legend_fontsize=7,\n",
    "    dpi=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b>:\n",
    "\n",
    "- Build a graph of spatial neighbors using a radius (e.g. 150 pixels) and plot the results using 'sq.pl.spatial_scatter'. Inspect the neighbor relationships in both directions for the first 10 cells. How does this compare to the results for 6-nearest neighbors spatial graph? Do the same for Delaunay triangulation.\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal the solution</summary>\n",
    "\n",
    "```python\n",
    "# radius-based spatial graphs\n",
    "from harpy.utils._keys import _REGION_KEY\n",
    "\n",
    "sq.gr.spatial_neighbors(\n",
    "    adata=sdata[\"table_transcriptomics_score_genes\"], \n",
    "    coord_type=\"generic\", # Set to 'generic' for targeted spatial transcriptomics\n",
    "    n_neighs=6, # Only used when delaunay = False\n",
    "    radius=150, # To compute the neighbors based on the radius\n",
    "    delaunay=False, # Whether to compute the graph from Delaunay triangulation\n",
    "    set_diag=False, # Whether to set the diagonal of the connectivity matrix to 1 (i.e. whether cells should be considered neighbors of themselves).\n",
    "    key_added=\"radius\"\n",
    ")\n",
    "\n",
    "region = sdata[\"table_transcriptomics_score_genes\"].obs[_REGION_KEY].cat.categories.to_list()\n",
    "\n",
    "sdata = hp.tb.add_table_layer(\n",
    "    sdata,\n",
    "    adata=sdata.tables[\"table_transcriptomics_score_genes\"],\n",
    "    output_layer=\"table_transcriptomics_squidpy\",\n",
    "    region=region, # A list of regions to associate with the table data. Typically this is all unique elements in adata.obs[_REGION_KEY].\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "print('Inspect number of neighbors (for first 10 cells):')\n",
    "display(sdata.tables['table_transcriptomics_squidpy'].obsp['radius_connectivities'].toarray().sum(axis=1)[0:10])\n",
    "\n",
    "print('Inspect for every cell how many cells have it as a neighbor (for first 10 cells):')\n",
    "display(sdata.tables['table_transcriptomics_squidpy'].obsp['radius_connectivities'].toarray().sum(axis=0)[0:10])\n",
    "\n",
    "sq.pl.spatial_scatter(\n",
    "    sdata.tables[\"table_transcriptomics_squidpy\"],\n",
    "    shape=None,\n",
    "    color=\"annotation\",\n",
    "    connectivity_key=\"radius_connectivities\",\n",
    "    size=30,\n",
    "    figsize=(15,15),\n",
    "    legend_loc='best',\n",
    "    legend_fontsize=7,\n",
    "    dpi=300\n",
    ")\n",
    "\n",
    "# Delaunay triangulation\n",
    "from harpy.utils._keys import _REGION_KEY\n",
    "\n",
    "sq.gr.spatial_neighbors(\n",
    "    adata=sdata[\"table_transcriptomics_score_genes\"], \n",
    "    coord_type=\"generic\", # Set to 'generic' for targeted spatial transcriptomics\n",
    "    n_neighs=6, # Only used when delaunay = False\n",
    "    radius=None, # To compute the neighbors based on the radius\n",
    "    delaunay=True, # Whether to compute the graph from Delaunay triangulation\n",
    "    set_diag=False, # Whether to set the diagonal of the connectivity matrix to 1 (i.e. whether cells should be considered neighbors of themselves).\n",
    "    key_added=\"delaunay\"\n",
    ")\n",
    "\n",
    "region = sdata[\"table_transcriptomics_score_genes\"].obs[_REGION_KEY].cat.categories.to_list()\n",
    "\n",
    "sdata = hp.tb.add_table_layer(\n",
    "    sdata,\n",
    "    adata=sdata.tables[\"table_transcriptomics_score_genes\"],\n",
    "    output_layer=\"table_transcriptomics_squidpy\",\n",
    "    region=region, # A list of regions to associate with the table data. Typically this is all unique elements in adata.obs[_REGION_KEY].\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "print('Inspect number of neighbors (for first 10 cells):')\n",
    "display(sdata.tables['table_transcriptomics_squidpy'].obsp['delaunay_connectivities'].toarray().sum(axis=1)[0:10])\n",
    "\n",
    "print('Inspect for every cell how many cells have it as a neighbor (for first 10 cells):')\n",
    "display(sdata.tables['table_transcriptomics_squidpy'].obsp['delaunay_connectivities'].toarray().sum(axis=0)[0:10])\n",
    "\n",
    "sq.pl.spatial_scatter(\n",
    "    sdata.tables[\"table_transcriptomics_squidpy\"],\n",
    "    shape=None,\n",
    "    color=\"annotation\",\n",
    "    connectivity_key=\"delaunay_connectivities\",\n",
    "    size=30,\n",
    "    figsize=(15,15),\n",
    "    legend_loc='best',\n",
    "    legend_fontsize=7,\n",
    "    dpi=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.2 Neighborhood enrichment analysis\n",
    "Then we can calculate the neighborhood enrichment score with squidpy.gr.nhood_enrichment. This function will generate a dictionary stored in adata.uns['annotated_nhood_enrichment'] that will contain a z scores matrix and and a count matrix.\n",
    "\n",
    "The count matrix represents how often each pair of cell types are neighbors in the dataset. Each row in this count matrix represents a cell type, and each column shows how many times its connected to other cell types.\n",
    "\n",
    "For each pair of cell types, the observed counts from the original data are compared to, for example, 1000 permutations (depending on the n_perms argument) and a z-score is calculated. The z-score is a measure of how many standard deviations the observed count deviates from the distribution generated by random permutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate neighborhood enrichment\n",
    "sq.gr.nhood_enrichment(\n",
    "    sdata.tables[\"table_transcriptomics_squidpy\"], \n",
    "    cluster_key='annotation', \n",
    "    connectivity_key='KNN'\n",
    ")\n",
    "\n",
    "# Add table layer to back to zarr\n",
    "sdata = hp.tb.add_table_layer(\n",
    "    sdata,\n",
    "    adata=sdata.tables[\"table_transcriptomics_squidpy\"],\n",
    "    output_layer=\"table_transcriptomics_squidpy\",\n",
    "    region=region,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# NOTE: Also see harpy.tb.nhood_enrichment and harpy.pl.nhood_enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot neighborhood enrichment\n",
    "sq.pl.nhood_enrichment(\n",
    "    sdata.tables[\"table_transcriptomics_squidpy\"],\n",
    "    cluster_key='annotation', \n",
    "    mode='zscore',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.3 Spatial autocorrelation\n",
    "Morans I can be understood as the Pearson correlation between the value at each location and the average value at its neighbors. Just like Pearson correlation, Morans I is bound between -1 and 1, where positive value indicates positive spatial autocorrelation and negative value indicates negative spatial autocorrelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Morans I global spatial auto-correlation statistics\n",
    "sq.gr.spatial_autocorr(\n",
    "    adata=sdata.tables[\"table_transcriptomics_squidpy\"],\n",
    "    mode=\"moran\",\n",
    "    n_perms=100,\n",
    "    n_jobs=1,\n",
    "    connectivity_key='KNN_connectivities'\n",
    ")\n",
    "\n",
    "# Add table layer to back to zarr\n",
    "sdata = hp.tb.add_table_layer(\n",
    "    sdata,\n",
    "    adata=sdata.tables[\"table_transcriptomics_squidpy\"],\n",
    "    output_layer=\"table_transcriptomics_squidpy\",\n",
    "    region=region,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect highest Moran's I scores\n",
    "sdata.tables[\"table_transcriptomics_squidpy\"].uns[\"moranI\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect lowest Moran's I scores\n",
    "sdata.tables[\"table_transcriptomics_squidpy\"].uns[\"moranI\"].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's inspect the spatial expression pattersn for the 9 highest Moran's I scores.\n",
    "color_vars = sdata.tables[\"table_transcriptomics_squidpy\"].uns[\"moranI\"].index[0:9]\n",
    "\n",
    "with rc_context({\"figure.figsize\": (4, 5)}):\n",
    "    sq.pl.spatial_scatter(\n",
    "        sdata.tables[\"table_transcriptomics_squidpy\"],\n",
    "        shape=None,\n",
    "        color=color_vars,\n",
    "        size=5,\n",
    "        ncols=3,\n",
    "        dpi=300\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAPs of 9 highest Moran's I scores\n",
    "with rc_context({\"figure.figsize\": (4, 4)}):\n",
    "    sc.pl.umap(\n",
    "        sdata.tables[\"table_transcriptomics_clustered\"], \n",
    "        color=color_vars, \n",
    "        ncols=3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 TissUUmaps\n",
    "\n",
    "TissUUmaps is a handy visualization software that allows easy interactive exploration of your spatial data. It can be used to visualize data from an AnnData .h5ad file or from a csv-file. You can also simultaneously visualize images (multiple file types, including tiff) and regions (GeoJSON). \n",
    "\n",
    "It can be installed using this link: https://tissuumaps.github.io/installation/ \\\n",
    "Documentation can be found here: https://tissuumaps.github.io/TissUUmaps-docs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export image as tiff\n",
    "from skimage.io import imsave\n",
    "\n",
    "if not unit_testing:\n",
    "\n",
    "    # Save AnnData as h5ad\n",
    "    sdata.tables[\"table_transcriptomics_squidpy\"].write(os.path.join(OUTPUT_DIR, 'adata.h5ad'))\n",
    "\n",
    "    img = sdata.images['clahe'].data.compute()\n",
    "    imsave(os.path.join(OUTPUT_DIR, \"clahe.tiff\"), img)\n",
    "\n",
    "    # Export shapes layer as GeoJSON\n",
    "    sdata.shapes['segmentation_mask_boundaries'].to_file(os.path.join(OUTPUT_DIR, \"segmantation_mask_boundaries.geojson\"), driver=\"GeoJSON\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Segmentation-free analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we create new labels and shapes layers for a hexagonal grid \n",
    "shape = (12864, 10720)\n",
    "\n",
    "size = 50 # radius of the hexagon, or size length of the square.\n",
    "\n",
    "sdata = hp.im.add_grid_labels_layer(\n",
    "    sdata, \n",
    "    shape=shape, \n",
    "    size=size, \n",
    "    output_shapes_layer=f\"shapes_spots_{size}um\", \n",
    "    output_labels_layer=f\"labels_spots_{size}um\", \n",
    "    grid_type='hexagon', # Set to 'square' for square grid\n",
    "    offset=(0, 0), \n",
    "    chunks=1024, \n",
    "    client=None, \n",
    "    transformations=None, \n",
    "    scale_factors=(2, 2, 2, 2),\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate transcripts\n",
    "sdata = hp.tb.allocate(\n",
    "    sdata=sdata,\n",
    "    labels_layer=f\"labels_spots_{size}um\",\n",
    "    points_layer=\"transcripts\", # The points layer in `sdata` that contains the transcripts.\n",
    "    output_layer=\"table_transcriptomics_hex\", # The table layer in `sdata` in which to save the AnnData object with the transcripts counts per cell.\n",
    "    update_shapes_layers=False,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# Perform preprocessing.\n",
    "sdata = hp.tb.preprocess_transcriptomics(\n",
    "    sdata,\n",
    "    labels_layer=f\"labels_spots_{size}um\",\n",
    "    table_layer=\"table_transcriptomics_hex\",\n",
    "    output_layer=\"table_transcriptomics_hex_preprocessed\", # write results to a new slot, we could also write to the same slot (when passing overwrite==True).\n",
    "    min_counts=10,\n",
    "    min_cells=5,\n",
    "    size_norm=True,\n",
    "    highly_variable_genes=False,  # If True, will only retain highly variable genes. This can be used for transcriptome-wide methods.\n",
    "    max_value_scale=10, # The maximum value to which data will be scaled\n",
    "    n_comps=50, # Number of principal components to calculate.\n",
    "    overwrite=True,\n",
    "    update_shapes_layers=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "# Leiden clustering\n",
    "sdata = hp.tb.leiden(\n",
    "    sdata,\n",
    "    labels_layer=f\"labels_spots_{size}um\",\n",
    "    table_layer=\"table_transcriptomics_hex_preprocessed\",\n",
    "    output_layer=\"table_transcriptomics_hex_preprocessed\",\n",
    "    calculate_umap=True,\n",
    "    calculate_neighbors=True,\n",
    "    n_pcs=17, # The number of principal components to use when calculating neighbors.\n",
    "    n_neighbors=35, # The number of neighbors to consider when calculating neighbors.\n",
    "    resolution=0.8,\n",
    "    rank_genes=True,\n",
    "    key_added=\"leiden\",\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# Plot UMAP\n",
    "sc.pl.umap(sdata.tables[\"table_transcriptomics_hex_preprocessed\"], color=[\"leiden\"], show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot clusters spatially\n",
    "hp.pl.plot_shapes(\n",
    "    sdata,\n",
    "    img_layer=\"clahe\",\n",
    "    table_layer=\"table_transcriptomics_hex_preprocessed\",\n",
    "    column=\"leiden\",\n",
    "    shapes_layer=f\"shapes_spots_{size}um\",\n",
    "    alpha=1.0,\n",
    "    linewidth=0,\n",
    "    # crd=[2000, 4000, 2000, 4000]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from harpy.utils._keys import _REGION_KEY\n",
    "import squidpy as sq\n",
    "\n",
    "sq.gr.spatial_neighbors(\n",
    "    adata=sdata[\"table_transcriptomics_hex_preprocessed\"], \n",
    "    coord_type=\"grid\", # Set to 'generic' for targeted spatial transcriptomics\n",
    "    n_neighs=6, # Only used when delaunay = False\n",
    "    radius=None, # To compute the neighbors based on the radius\n",
    "    delaunay=False, # Whether to compute the graph from Delaunay triangulation\n",
    "    set_diag=False, # Whether to set the diagonal of the connectivity matrix to 1 (i.e. whether cells should be considered neighbors of themselves).\n",
    "    key_added=None\n",
    ")\n",
    "\n",
    "region = sdata[\"table_transcriptomics_hex_preprocessed\"].obs[_REGION_KEY].cat.categories.to_list()\n",
    "\n",
    "sdata = hp.tb.add_table_layer(\n",
    "    sdata,\n",
    "    adata=sdata.tables[\"table_transcriptomics_hex_preprocessed\"],\n",
    "    output_layer=\"table_transcriptomics_hex_preprocessed\",\n",
    "    region=region, # A list of regions to associate with the table data. Typically this is all unique elements in adata.obs[_REGION_KEY].\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Morans I global spatial auto-correlation statistics\n",
    "sq.gr.spatial_autocorr(\n",
    "    adata=sdata.tables[\"table_transcriptomics_hex_preprocessed\"],\n",
    "    mode=\"moran\",\n",
    "    n_perms=100,\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "# Add table layer to back to zarr\n",
    "sdata = hp.tb.add_table_layer(\n",
    "    sdata,\n",
    "    adata=sdata.tables[\"table_transcriptomics_hex_preprocessed\"],\n",
    "    output_layer=\"table_transcriptomics_hex_preprocessed\",\n",
    "    region=region,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's inspect the spatial expression pattersn for the 9 highest Moran's I scores.\n",
    "color_vars = sdata.tables[\"table_transcriptomics_hex_preprocessed\"].uns[\"moranI\"].index[0:9]\n",
    "from matplotlib.pyplot import rc_context\n",
    "with rc_context({\"figure.figsize\": (4, 5)}):\n",
    "    sq.pl.spatial_scatter(\n",
    "        sdata.tables[\"table_transcriptomics_hex_preprocessed\"],\n",
    "        shape=None,\n",
    "        color=color_vars,\n",
    "        size=5,\n",
    "        ncols=3,\n",
    "        dpi=300\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.pl.spatial_scatter(\n",
    "    sdata.tables[\"table_transcriptomics_hex_preprocessed\"],\n",
    "    shape=None,\n",
    "    color=\"leiden\",\n",
    "    connectivity_key=\"spatial_connectivities\",\n",
    "    size=30,\n",
    "    figsize=(15,15),\n",
    "    legend_loc='best',\n",
    "    legend_fontsize=7,\n",
    "    dpi=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
